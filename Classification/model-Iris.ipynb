{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Modeling\n",
    "Do your work for these exercises in either a notebook or a python script named model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from acquire import get_titanic_data\n",
    "from prepare import prep_titanic_data\n",
    "\n",
    "df = get_titanic_data()\n",
    "df = prep_titanic_data(df)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "1. Fit the logistic regression classifier to your training sample and transform, i.e. make predictions on the training sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values in the `age` column.\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['pclass','age','fare','sibsp','parch']]\n",
    "y = df[['survived']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .30, random_state = 123)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. make the thing\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# 2. fit the thing\n",
    "scaler.fit(X_train[['age', 'fare']])\n",
    "\n",
    "# 3. use the thing\n",
    "X_train[['age', 'fare']] = scaler.transform(X_train[['age', 'fare']])\n",
    "X_test[['age', 'fare']] = scaler.transform(X_test[['age', 'fare']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model\n",
    "#### Create the logistic regression object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logit = LogisticRegression(C=1, class_weight={1:2}, random_state = 123, solver='saga')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit the model to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print the coefficients and intercept of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficient: \\n', logit.coef_)\n",
    "print()\n",
    "print('Intercept: \\n', logit.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Evaluate your in-sample results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimate whether or not a passenger would survive, using the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logit.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimate the probability of a passenger surviving, using the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = logit.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['prediction'] = logit.predict(X_train[['pclass','age','fare','sibsp','parch']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(y_train.survived == X_train.prediction).sum() / y_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit.score(X_train[['pclass','age','fare','sibsp','parch']], y_train.survived)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model\n",
    "#### Compute the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit.score(X_train.drop(columns='prediction'), y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(confusion_matrix(y_train.survived, X_train.prediction),\n",
    "             columns=['Pred -', 'Pred +'], index=['Actual -', 'Actual +'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute Precision, Recall, F1-score, and Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model\n",
    "#### Compute the accuracy of the model when run on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of Logistic Regression classifier on test set: {:.2f}'\n",
    "     .format(logit.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(confusion_matrix(y_train.survived, X_train.prediction),\n",
    "             columns=['Pred -', 'Pred +'], index=['Actual -', 'Actual +'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TN = df['Pred -'][0] # 190\n",
    "FP = df['Pred +'][0] #103\n",
    "FN = df['Pred -'][1] # 50\n",
    "TP = df['Pred +'][1] # 156\n",
    "total = TN + FP + FN + TP\n",
    "\n",
    "print('True Negative = ', TN)\n",
    "print('False Positive = ', FP)\n",
    "print('False Negative = ', FN)\n",
    "print('True Positive = ', TP)\n",
    "print('Total = ', total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy = # correct / total \n",
    "#          = (true positive + true negative) / total\n",
    "accuracy = (TP + TN) / total\n",
    "print('Accuracy = ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall = Sensitivity\n",
    "#      = true positive rate \n",
    "#      = true positive / (true positive + false negative) \n",
    "recall = TP / (TP + FN)\n",
    "print('Recall = ', recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specificity = false positive rate\n",
    "#      = false positive / (false positive + true negative)\n",
    "specificity = FP / (FP + TN)\n",
    "print('Specificity = ', specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true negative rate = true negative / (true negative + false positive)\n",
    "trueneg = TN / (TN + FP)\n",
    "print('True Negative Rate = ', trueneg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# false negative rate = false negative / (false negaitve + true positive)\n",
    "falseneg = FN / (FN + TP)\n",
    "print('False Negative Rate = ', falseneg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision = true positive / (true positive + false positive)\n",
    "precision = TP / (TP + FP)\n",
    "print('Precision = ', precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = (precision + recall) / 2\n",
    "print('f1-score is ', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "died = TN + FP\n",
    "lived = TP + FN\n",
    "print(died, 'people died and', lived, 'people lived.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Look in the scikit-learn documentation to research the solver parameter. What is your best option(s) for the particular problem you are trying to solve and the data to be used?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class sklearn.linear_model.LogisticRegression(\n",
    "    penalty=’l2’, \n",
    "    dual=False, \n",
    "    tol=0.0001, \n",
    "    C=1.0, \n",
    "    fit_intercept=True, \n",
    "    intercept_scaling=1, \n",
    "    class_weight=None, \n",
    "    random_state=None, \n",
    "    solver=’warn’, \n",
    "    max_iter=100, \n",
    "    multi_class=’warn’, \n",
    "    verbose=0, \n",
    "    warm_start=False, \n",
    "    n_jobs=None)\n",
    "    \n",
    "solver : str, {‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’}, default: ‘liblinear’.\n",
    "Algorithm to use in the optimization problem.\n",
    "\n",
    "- For small datasets, ‘liblinear’ is a good choice, whereas ‘sag’ and ‘saga’ are faster for large ones.\n",
    "- For multiclass problems, only ‘newton-cg’, ‘sag’, ‘saga’ and ‘lbfgs’ handle multinomial loss; ‘liblinear’ is limited to one-versus-rest schemes.\n",
    "\n",
    "‘newton-cg’, ‘lbfgs’ and ‘sag’ only handle L2 penalty, whereas ‘liblinear’ and ‘saga’ handle L1 penalty.\n",
    "Note that ‘sag’ and ‘saga’ fast convergence is only guaranteed on features with approximately the same scale. You can preprocess the data with a scaler from sklearn.preprocessing.\n",
    "\n",
    "We just want the default!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Run through steps 2-4 using another solver (from question 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for saga solver:\n",
    "X_train = []\n",
    "df = get_titanic_data()\n",
    "df = prep_titanic_data(df)\n",
    "# Handle missing values in the `age` column.\n",
    "df.dropna(inplace=True)\n",
    "X = df[['pclass','age','fare','sibsp','parch']]\n",
    "y = df[['survived']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .30, random_state = 123)\n",
    "\n",
    "# 1. make the thing\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# 2. fit the thing\n",
    "scaler.fit(X_train[['age', 'fare']])\n",
    "\n",
    "# 3. use the thing\n",
    "X_train[['age', 'fare']] = scaler.transform(X_train[['age', 'fare']])\n",
    "X_test[['age', 'fare']] = scaler.transform(X_test[['age', 'fare']])\n",
    "\n",
    "\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "logit = LogisticRegression(C=1, class_weight={1:2}, random_state = 123, solver='saga')\n",
    "logit.fit(X_train, y_train)\n",
    "y_pred = logit.predict(X_train)\n",
    "y_pred_proba = logit.predict_proba(X_train)\n",
    "X_train['prediction'] = logit.predict(X_train[['pclass','age','fare','sibsp','parch']])\n",
    "# (y_train.survived == X_train.prediction).sum() / y_train.shape[0]\n",
    "# logit.score(X_train[['pclass','age','fare','sibsp','parch']], y_train.survived)\n",
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit.score(X_train.drop(columns='prediction'), y_train)))\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "df = pd.DataFrame(confusion_matrix(y_train.survived, X_train.prediction),\n",
    "             columns=['Pred -', 'Pred +'], index=['Actual -', 'Actual +'])\n",
    "print(classification_report(y_train, y_pred))\n",
    "TN = df['Pred -'][0] # 190\n",
    "FP = df['Pred +'][0] #103\n",
    "FN = df['Pred -'][1] # 50\n",
    "TP = df['Pred +'][1] # 156\n",
    "total = TN + FP + FN + TP\n",
    "\n",
    "print('True Negative = ', TN)\n",
    "print('False Positive = ', FP)\n",
    "print('False Negative = ', FN)\n",
    "print('True Positive = ', TP)\n",
    "print('Total = ', total)\n",
    "\n",
    "# Accuracy = # correct / total \n",
    "#          = (true positive + true negative) / total\n",
    "accuracy = (TP + TN) / total\n",
    "print('Accuracy = ', accuracy)\n",
    "\n",
    "# Recall = Sensitivity\n",
    "#      = true positive rate \n",
    "#      = true positive / (true positive + false negative) \n",
    "recall = TP / (TP + FN)\n",
    "print('Recall = ', recall)\n",
    "\n",
    "# Specificity = false positive rate\n",
    "#      = false positive / (false positive + true negative)\n",
    "specificity = FP / (FP + TN)\n",
    "print('Specificity = ', specificity)\n",
    "\n",
    "# true negative rate = true negative / (true negative + false positive)\n",
    "trueneg = TN / (TN + FP)\n",
    "print('True Negative Rate = ', trueneg)\n",
    "\n",
    "# false negative rate = false negative / (false negaitve + true positive)\n",
    "falseneg = FN / (FN + TP)\n",
    "print('False Negative Rate = ', falseneg)\n",
    "\n",
    "# precision = true positive / (true positive + false positive)\n",
    "precision = TP / (TP + FP)\n",
    "print('Precision = ', precision)\n",
    "\n",
    "f1 = (precision + recall) / 2\n",
    "print('f1-score is ', f1)\n",
    "\n",
    "died = TN + FP\n",
    "lived = TP + FN\n",
    "print(died, 'people died and', lived, 'people lived.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# liblinear solver\n",
    "X_train = []\n",
    "df = get_titanic_data()\n",
    "df = prep_titanic_data(df)\n",
    "# Handle missing values in the `age` column.\n",
    "df.dropna(inplace=True)\n",
    "X = df[['pclass','age','fare','sibsp','parch']]\n",
    "y = df[['survived']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .30, random_state = 123)\n",
    "\n",
    "# 1. make the thing\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# 2. fit the thing\n",
    "scaler.fit(X_train[['age', 'fare']])\n",
    "\n",
    "# 3. use the thing\n",
    "X_train[['age', 'fare']] = scaler.transform(X_train[['age', 'fare']])\n",
    "X_test[['age', 'fare']] = scaler.transform(X_test[['age', 'fare']])\n",
    "\n",
    "\n",
    "\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "logit = LogisticRegression(C=1, class_weight={1:2}, random_state = 123, solver='liblinear')\n",
    "logit.fit(X_train, y_train)\n",
    "y_pred = logit.predict(X_train)\n",
    "y_pred_proba = logit.predict_proba(X_train)\n",
    "X_train['prediction'] = logit.predict(X_train[['pclass','age','fare','sibsp','parch']])\n",
    "# (y_train.survived == X_train.prediction).sum() / y_train.shape[0]\n",
    "# logit.score(X_train[['pclass','age','fare','sibsp','parch']], y_train.survived)\n",
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit.score(X_train.drop(columns='prediction'), y_train)))\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "df = pd.DataFrame(confusion_matrix(y_train.survived, X_train.prediction),\n",
    "             columns=['Pred -', 'Pred +'], index=['Actual -', 'Actual +'])\n",
    "print(classification_report(y_train, y_pred))\n",
    "TN = df['Pred -'][0] # 190\n",
    "FP = df['Pred +'][0] #103\n",
    "FN = df['Pred -'][1] # 50\n",
    "TP = df['Pred +'][1] # 156\n",
    "total = TN + FP + FN + TP\n",
    "\n",
    "print('True Negative = ', TN)\n",
    "print('False Positive = ', FP)\n",
    "print('False Negative = ', FN)\n",
    "print('True Positive = ', TP)\n",
    "print('Total = ', total)\n",
    "\n",
    "# Accuracy = # correct / total \n",
    "#          = (true positive + true negative) / total\n",
    "accuracy = (TP + TN) / total\n",
    "print('Accuracy = ', accuracy)\n",
    "\n",
    "# Recall = Sensitivity\n",
    "#      = true positive rate \n",
    "#      = true positive / (true positive + false negative) \n",
    "recall = TP / (TP + FN)\n",
    "print('Recall = ', recall)\n",
    "\n",
    "# Specificity = false positive rate\n",
    "#      = false positive / (false positive + true negative)\n",
    "specificity = FP / (FP + TN)\n",
    "print('Specificity = ', specificity)\n",
    "\n",
    "# true negative rate = true negative / (true negative + false positive)\n",
    "trueneg = TN / (TN + FP)\n",
    "print('True Negative Rate = ', trueneg)\n",
    "\n",
    "# false negative rate = false negative / (false negaitve + true positive)\n",
    "falseneg = FN / (FN + TP)\n",
    "print('False Negative Rate = ', falseneg)\n",
    "\n",
    "# precision = true positive / (true positive + false positive)\n",
    "precision = TP / (TP + FP)\n",
    "print('Precision = ', precision)\n",
    "\n",
    "f1 = (precision + recall) / 2\n",
    "print('f1-score is ', f1)\n",
    "\n",
    "died = TN + FP\n",
    "lived = TP + FN\n",
    "print(died, 'people died and', lived, 'people lived.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# newton-cg solver\n",
    "X_train = []\n",
    "df = get_titanic_data()\n",
    "df = prep_titanic_data(df)\n",
    "# Handle missing values in the `age` column.\n",
    "df.dropna(inplace=True)\n",
    "X = df[['pclass','age','fare','sibsp','parch']]\n",
    "y = df[['survived']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .30, random_state = 123)\n",
    "\n",
    "# 1. make the thing\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# 2. fit the thing\n",
    "scaler.fit(X_train[['age', 'fare']])\n",
    "\n",
    "# 3. use the thing\n",
    "X_train[['age', 'fare']] = scaler.transform(X_train[['age', 'fare']])\n",
    "X_test[['age', 'fare']] = scaler.transform(X_test[['age', 'fare']])\n",
    "\n",
    "\n",
    "\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "logit = LogisticRegression(C=1, class_weight={1:2}, random_state = 123, solver='newton-cg')\n",
    "logit.fit(X_train, y_train)\n",
    "y_pred = logit.predict(X_train)\n",
    "y_pred_proba = logit.predict_proba(X_train)\n",
    "X_train['prediction'] = logit.predict(X_train[['pclass','age','fare','sibsp','parch']])\n",
    "# (y_train.survived == X_train.prediction).sum() / y_train.shape[0]\n",
    "# logit.score(X_train[['pclass','age','fare','sibsp','parch']], y_train.survived)\n",
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit.score(X_train.drop(columns='prediction'), y_train)))\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "df = pd.DataFrame(confusion_matrix(y_train.survived, X_train.prediction),\n",
    "             columns=['Pred -', 'Pred +'], index=['Actual -', 'Actual +'])\n",
    "print(classification_report(y_train, y_pred))\n",
    "TN = df['Pred -'][0] # 190\n",
    "FP = df['Pred +'][0] #103\n",
    "FN = df['Pred -'][1] # 50\n",
    "TP = df['Pred +'][1] # 156\n",
    "total = TN + FP + FN + TP\n",
    "\n",
    "print('True Negative = ', TN)\n",
    "print('False Positive = ', FP)\n",
    "print('False Negative = ', FN)\n",
    "print('True Positive = ', TP)\n",
    "print('Total = ', total)\n",
    "\n",
    "# Accuracy = # correct / total \n",
    "#          = (true positive + true negative) / total\n",
    "accuracy = (TP + TN) / total\n",
    "print('Accuracy = ', accuracy)\n",
    "\n",
    "# Recall = Sensitivity\n",
    "#      = true positive rate \n",
    "#      = true positive / (true positive + false negative) \n",
    "recall = TP / (TP + FN)\n",
    "print('Recall = ', recall)\n",
    "\n",
    "# Specificity = false positive rate\n",
    "#      = false positive / (false positive + true negative)\n",
    "specificity = FP / (FP + TN)\n",
    "print('Specificity = ', specificity)\n",
    "\n",
    "# true negative rate = true negative / (true negative + false positive)\n",
    "trueneg = TN / (TN + FP)\n",
    "print('True Negative Rate = ', trueneg)\n",
    "\n",
    "# false negative rate = false negative / (false negaitve + true positive)\n",
    "falseneg = FN / (FN + TP)\n",
    "print('False Negative Rate = ', falseneg)\n",
    "\n",
    "# precision = true positive / (true positive + false positive)\n",
    "precision = TP / (TP + FP)\n",
    "print('Precision = ', precision)\n",
    "\n",
    "f1 = (precision + recall) / 2\n",
    "print('f1-score is ', f1)\n",
    "\n",
    "died = TN + FP\n",
    "lived = TP + FN\n",
    "print(died, 'people died and', lived, 'people lived.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sag solver\n",
    "X_train = []\n",
    "df = get_titanic_data()\n",
    "df = prep_titanic_data(df)\n",
    "# Handle missing values in the `age` column.\n",
    "df.dropna(inplace=True)\n",
    "X = df[['pclass','age','fare','sibsp','parch']]\n",
    "y = df[['survived']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .30, random_state = 123)\n",
    "\n",
    "# 1. make the thing\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# 2. fit the thing\n",
    "scaler.fit(X_train[['age', 'fare']])\n",
    "\n",
    "# 3. use the thing\n",
    "X_train[['age', 'fare']] = scaler.transform(X_train[['age', 'fare']])\n",
    "X_test[['age', 'fare']] = scaler.transform(X_test[['age', 'fare']])\n",
    "\n",
    "\n",
    "\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "logit = LogisticRegression(C=1, class_weight={1:2}, random_state = 123, solver='sag')\n",
    "logit.fit(X_train, y_train)\n",
    "y_pred = logit.predict(X_train)\n",
    "y_pred_proba = logit.predict_proba(X_train)\n",
    "X_train['prediction'] = logit.predict(X_train[['pclass','age','fare','sibsp','parch']])\n",
    "# (y_train.survived == X_train.prediction).sum() / y_train.shape[0]\n",
    "# logit.score(X_train[['pclass','age','fare','sibsp','parch']], y_train.survived)\n",
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit.score(X_train.drop(columns='prediction'), y_train)))\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "df = pd.DataFrame(confusion_matrix(y_train.survived, X_train.prediction),\n",
    "             columns=['Pred -', 'Pred +'], index=['Actual -', 'Actual +'])\n",
    "print(classification_report(y_train, y_pred))\n",
    "TN = df['Pred -'][0] # 190\n",
    "FP = df['Pred +'][0] #103\n",
    "FN = df['Pred -'][1] # 50\n",
    "TP = df['Pred +'][1] # 156\n",
    "total = TN + FP + FN + TP\n",
    "\n",
    "print('True Negative = ', TN)\n",
    "print('False Positive = ', FP)\n",
    "print('False Negative = ', FN)\n",
    "print('True Positive = ', TP)\n",
    "print('Total = ', total)\n",
    "\n",
    "# Accuracy = # correct / total \n",
    "#          = (true positive + true negative) / total\n",
    "accuracy = (TP + TN) / total\n",
    "print('Accuracy = ', accuracy)\n",
    "\n",
    "# Recall = Sensitivity\n",
    "#      = true positive rate \n",
    "#      = true positive / (true positive + false negative) \n",
    "recall = TP / (TP + FN)\n",
    "print('Recall = ', recall)\n",
    "\n",
    "# Specificity = false positive rate\n",
    "#      = false positive / (false positive + true negative)\n",
    "specificity = FP / (FP + TN)\n",
    "print('Specificity = ', specificity)\n",
    "\n",
    "# true negative rate = true negative / (true negative + false positive)\n",
    "trueneg = TN / (TN + FP)\n",
    "print('True Negative Rate = ', trueneg)\n",
    "\n",
    "# false negative rate = false negative / (false negaitve + true positive)\n",
    "falseneg = FN / (FN + TP)\n",
    "print('False Negative Rate = ', falseneg)\n",
    "\n",
    "# precision = true positive / (true positive + false positive)\n",
    "precision = TP / (TP + FP)\n",
    "print('Precision = ', precision)\n",
    "\n",
    "f1 = (precision + recall) / 2\n",
    "print('f1-score is ', f1)\n",
    "\n",
    "died = TN + FP\n",
    "lived = TP + FN\n",
    "print(died, 'people died and', lived, 'people lived.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lbfgs solver\n",
    "X_train = []\n",
    "df = get_titanic_data()\n",
    "df = prep_titanic_data(df)\n",
    "# Handle missing values in the `age` column.\n",
    "df.dropna(inplace=True)\n",
    "X = df[['pclass','age','fare','sibsp','parch']]\n",
    "y = df[['survived']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .30, random_state = 123)\n",
    "\n",
    "# 1. make the thing\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# 2. fit the thing\n",
    "scaler.fit(X_train[['age', 'fare']])\n",
    "\n",
    "# 3. use the thing\n",
    "X_train[['age', 'fare']] = scaler.transform(X_train[['age', 'fare']])\n",
    "X_test[['age', 'fare']] = scaler.transform(X_test[['age', 'fare']])\n",
    "\n",
    "\n",
    "\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "logit = LogisticRegression(C=1, class_weight={1:2}, random_state = 123, solver='lbfgs')\n",
    "logit.fit(X_train, y_train)\n",
    "y_pred = logit.predict(X_train)\n",
    "y_pred_proba = logit.predict_proba(X_train)\n",
    "X_train['prediction'] = logit.predict(X_train[['pclass','age','fare','sibsp','parch']])\n",
    "# (y_train.survived == X_train.prediction).sum() / y_train.shape[0]\n",
    "# logit.score(X_train[['pclass','age','fare','sibsp','parch']], y_train.survived)\n",
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit.score(X_train.drop(columns='prediction'), y_train)))\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "df = pd.DataFrame(confusion_matrix(y_train.survived, X_train.prediction),\n",
    "             columns=['Pred -', 'Pred +'], index=['Actual -', 'Actual +'])\n",
    "print(classification_report(y_train, y_pred))\n",
    "TN = df['Pred -'][0] # 190\n",
    "FP = df['Pred +'][0] #103\n",
    "FN = df['Pred -'][1] # 50\n",
    "TP = df['Pred +'][1] # 156\n",
    "total = TN + FP + FN + TP\n",
    "\n",
    "print('True Negative = ', TN)\n",
    "print('False Positive = ', FP)\n",
    "print('False Negative = ', FN)\n",
    "print('True Positive = ', TP)\n",
    "print('Total = ', total)\n",
    "\n",
    "# Accuracy = # correct / total \n",
    "#          = (true positive + true negative) / total\n",
    "accuracy = (TP + TN) / total\n",
    "print('Accuracy = ', accuracy)\n",
    "\n",
    "# Recall = Sensitivity\n",
    "#      = true positive rate \n",
    "#      = true positive / (true positive + false negative) \n",
    "recall = TP / (TP + FN)\n",
    "print('Recall = ', recall)\n",
    "\n",
    "# Specificity = false positive rate\n",
    "#      = false positive / (false positive + true negative)\n",
    "specificity = FP / (FP + TN)\n",
    "print('Specificity = ', specificity)\n",
    "\n",
    "# true negative rate = true negative / (true negative + false positive)\n",
    "trueneg = TN / (TN + FP)\n",
    "print('True Negative Rate = ', trueneg)\n",
    "\n",
    "# false negative rate = false negative / (false negaitve + true positive)\n",
    "falseneg = FN / (FN + TP)\n",
    "print('False Negative Rate = ', falseneg)\n",
    "\n",
    "# precision = true positive / (true positive + false positive)\n",
    "precision = TP / (TP + FP)\n",
    "print('Precision = ', precision)\n",
    "\n",
    "f1 = (precision + recall) / 2\n",
    "print('f1-score is ', f1)\n",
    "\n",
    "died = TN + FP\n",
    "lived = TP + FN\n",
    "print(died, 'people died and', lived, 'people lived.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Which performs better on your in-sample data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I got the same results for all of the solvers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Save the best model in logit_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_fit = logit\n",
    "logit_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "1. Fit the decision tree classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pydataset import data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import tree\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from acquire import get_titanic_data\n",
    "from prepare import prep_titanic_data\n",
    "\n",
    "df = data('iris')\n",
    "\n",
    "df.columns = [col.lower().replace('.', '_') for col in df]\n",
    "\n",
    "X = df.drop(['species'],axis=1)\n",
    "y = df[['species']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .30, random_state = 123)\n",
    "\n",
    "# for classificaiton you can change the algorithm as gini or entropy \n",
    "# (information gain).  Default is gini.\n",
    "clf = DecisionTreeClassifier(criterion='gini', max_depth=3, random_state=123)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"for features...\")\n",
    "print(X_train.columns)\n",
    "print(clf.feature_importances_)\n",
    "print()\n",
    "\n",
    "y_pred = clf.predict(X_train)\n",
    "#print(y_pred[0:5]) # ['virginica' 'virginica' 'versicolor' 'setosa' 'setosa']\n",
    "\n",
    "y_pred_proba = clf.predict_proba(X_train)\n",
    "print(y_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Evaluate your in-sample results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "     .format(clf.score(X_train, y_train)))\n",
    "cm = confusion_matrix(y_train, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(y_train.species.unique())\n",
    "y_train.species.value_counts()\n",
    "\n",
    "labels = sorted(y_train.species.unique())\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y_train, y_pred), index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train, y_pred))\n",
    "print('Accuracy of Decision Tree classifier on test set: {:.2f}'\n",
    "     .format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## need to install graphviz to anaconda\n",
    "## example: \n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(iris.data, iris.target)\n",
    "\n",
    "import graphviz\n",
    "\n",
    "from graphviz import Graph\n",
    "\n",
    "dot_data = tree.export_graphviz(clf, out_file=None) \n",
    "graph = graphviz.Source(dot_data) \n",
    "\n",
    "graph.render('iris_decision_tree2', view=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Run through steps 2-4 using entropy as your measure of impurity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pydataset import data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import tree\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from acquire import get_iris_data\n",
    "from prepare import prep_iris_data\n",
    "\n",
    "df = data('iris')\n",
    "\n",
    "df.columns = [col.lower().replace('.', '_') for col in df]\n",
    "\n",
    "X = df.drop(['species'],axis=1)\n",
    "y = df[['species']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .30, random_state = 123)\n",
    "\n",
    "# for classificaiton you can change the algorithm as gini or entropy \n",
    "# (information gain).  Default is gini.\n",
    "clf = DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=123)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_train)\n",
    "#print(y_pred[0:5]) # ['virginica' 'virginica' 'versicolor' 'setosa' 'setosa']\n",
    "\n",
    "y_pred_proba = clf.predict_proba(X_train)\n",
    "\n",
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "     .format(clf.score(X_train, y_train)))\n",
    "cm = confusion_matrix(y_train, y_pred)\n",
    "\n",
    "sorted(y_train.species.unique())\n",
    "y_train.species.value_counts()\n",
    "\n",
    "labels = sorted(y_train.species.unique())\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y_train, y_pred), index=labels, columns=labels)\n",
    "\n",
    "print(classification_report(y_train, y_pred))\n",
    "print('Accuracy of Decision Tree classifier on test set: {:.2f}'\n",
    "     .format(clf.score(X_test, y_test)))\n",
    "\n",
    "cm = pd.DataFrame(confusion_matrix(y_train, y_pred), index=labels, columns=labels)\n",
    "print(classification_report(y_train, y_pred))\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## need to install graphviz to anaconda\n",
    "## example: \n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(iris.data, iris.target)\n",
    "\n",
    "import graphviz\n",
    "\n",
    "from graphviz import Graph\n",
    "\n",
    "dot_data = tree.export_graphviz(clf, out_file=None) \n",
    "graph = graphviz.Source(dot_data) \n",
    "\n",
    "graph.render('iris_decision_tree2', view=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Which performs better on your in-sample data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They are the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Save the best model in tree_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_fit = clf\n",
    "tree_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN\n",
    "1. Fit the K-Nearest Neighbors classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['species', 'sepal_length', 'sepal_width', 'petal_length', 'petal_width',\n",
       "       'species_encode'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pydataset import data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import tree\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from acquire import get_iris_data\n",
    "from prepare import prep_iris_data\n",
    "\n",
    "df = prep_iris_data(get_iris_data())\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from acquire import get_iris_data\n",
    "from prepare import prep_iris_data\n",
    "\n",
    "df = prep_iris_data(get_iris_data())\n",
    "\n",
    "df.dropna(inplace=True) # handle missing age values\n",
    "\n",
    "X = df[['pclass','age','fare','sibsp','parch']]\n",
    "y = df[['survived']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .30, random_state = 123)\n",
    "\n",
    "# weights = ['uniform', 'density']\n",
    "knn = KNeighborsClassifier(n_neighbors=5, weights='uniform')\n",
    "# choosing to be closest to five nearest neighbors\n",
    "# could weight features\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred = knn.predict(X_train)\n",
    "\n",
    "y_pred_proba = knn.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Evaluate your results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of KNN classifier on training set: {:.2f}'\n",
    "     .format(knn.score(X_train, y_train)))\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of KNN classifier on training set: {:.2f}'\n",
    "     .format(knn.score(X_train, y_train)))\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "print(classification_report(y_train, y_pred))\n",
    "print('Accuracy of KNN classifier on test set: {:.2f}'\n",
    "     .format(knn.score(X_test, y_test)))\n",
    "# print(confusion_matrix(y_test, y_pred))\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Run through steps 1-3 setting k to 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights = ['uniform', 'density']\n",
    "knn = KNeighborsClassifier(n_neighbors=10, weights='uniform')\n",
    "# choosing to be closest to five nearest neighbors\n",
    "# could weight features\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred = knn.predict(X_train)\n",
    "\n",
    "y_pred_proba = knn.predict_proba(X_train)\n",
    "\n",
    "print('Accuracy of KNN classifier on training set: {:.2f}'\n",
    "     .format(knn.score(X_train, y_train)))\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "print(classification_report(y_train, y_pred))\n",
    "\n",
    "print('Accuracy of KNN classifier on test set: {:.2f}'\n",
    "     .format(knn.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Run through setps 1-3 setting k to 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights = ['uniform', 'density']\n",
    "knn = KNeighborsClassifier(n_neighbors=20, weights='uniform')\n",
    "# choosing to be closest to five nearest neighbors\n",
    "# could weight features\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred = knn.predict(X_train)\n",
    "\n",
    "y_pred_proba = knn.predict_proba(X_train)\n",
    "\n",
    "print('Accuracy of KNN classifier on training set: {:.2f}'\n",
    "     .format(knn.score(X_train, y_train)))\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "print(classification_report(y_train, y_pred))\n",
    "\n",
    "print('Accuracy of KNN classifier on test set: {:.2f}'\n",
    "     .format(knn.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The K-Nearest Neighbor mode with k = 5 was the best fit on my in-sample data with 76% accuracy, but the test data only yielded a 67% accuracy. The rest of the metrics look comparable. I guess I'll save k = 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Save the best model in knn_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_fit = KNeighborsClassifier(n_neighbors=5, weights='uniform')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "1. Fit the Random Forest classifier to your training sample and transform (i.e. make predictions on the training sample) setting the random_state accordingly and setting min_samples_leaf = 1 and max_depth = 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from acquire import get_titanic_data\n",
    "from prepare import prep_titanic_data\n",
    "\n",
    "df = prep_titanic_data(get_titanic_data())\n",
    "\n",
    "# Handle missing age values\n",
    "df.dropna(inplace=True)\n",
    "print('number of nulls = ')\n",
    "print(df.isnull().sum())\n",
    "print()\n",
    "\n",
    "X = df[['pclass','age','fare','sibsp','parch']]\n",
    "y = df.survived\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .30, random_state = 123)\n",
    "\n",
    "# setting the random_state accordingly and \n",
    "# setting min_samples_leaf = 1 and max_depth = 20.\n",
    "rf = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=1,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=20, \n",
    "                            random_state=123)\n",
    "# min_samples_leaf is set to only 3 because dataset is small\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "print('this shows gini-index, shows you the importance of each feature in order')\n",
    "print('shows that fare is biggest indicator of survival')\n",
    "print(\"for features ['pclass','age','fare','sibsp','parch']:\")\n",
    "print(rf.feature_importances_)\n",
    "\n",
    "\n",
    "y_pred = rf.predict(X_train)\n",
    "\n",
    "y_pred_proba = rf.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Evaluate your results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "     .format(rf.score(X_train, y_train)))\n",
    "print()\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "# y_train is rows\n",
    "# y_pred is columns\n",
    "\n",
    "# these numbers are from lesson... need to be changed...\n",
    "# 248 - pred died, died     |45 -  pred to survive, died\n",
    "# 79 - pred died, survived  |127 - pred to survive, survived\n",
    "\n",
    "# accuracy = (248 + 127) / (248 + 79 + 45 + 127)\n",
    "# recall of surviving = sensitivity = 127 / (79 + 127)\n",
    "# recall of not surviving = specificity = 248 / (248 + 5)\n",
    "# precision of surviving = 127 / (45 + 127)\n",
    "# precision of not surviving = 248 / (248 + 79)\n",
    "# false negative = 79 / (248 + 79)\n",
    "\n",
    "print()\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of random forest classifier on TRAIN datat: {:.2f}'\n",
    "     .format(rf.score(X_train, y_train)))\n",
    "print()\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "print()\n",
    "print(classification_report(y_train, y_pred))\n",
    "\n",
    "print('Accuracy of output when model is run on TEST data:')\n",
    "print(rf.score(X_test, y_test))\n",
    "# print()\n",
    "# print(confusion_matrix(y_train, y_pred))\n",
    "# print()\n",
    "# print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Run through steps increasing your min_samples_leaf to 5 and decreasing your max_depth to 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the random_state accordingly and \n",
    "# setting min_samples_leaf = 5 and max_depth = 3.\n",
    "rf = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=5,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=3, \n",
    "                            random_state=123)\n",
    "# min_samples_leaf is set to only 3 because dataset is small\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "print('this shows gini-index, shows you the importance of each feature in order')\n",
    "print('shows that fare is biggest indicator of survival')\n",
    "print(\"for features ['pclass','age','fare','sibsp','parch']:\")\n",
    "print(rf.feature_importances_)\n",
    "print()\n",
    "\n",
    "y_pred = rf.predict(X_train)\n",
    "\n",
    "y_pred_proba = rf.predict_proba(X_train)\n",
    "\n",
    "# y_train is rows\n",
    "# y_pred is columns\n",
    "\n",
    "# these numbers are from lesson... need to be changed...\n",
    "# 248 - pred died, died     |45 -  pred to survive, died\n",
    "# 79 - pred died, survived  |127 - pred to survive, survived\n",
    "\n",
    "# accuracy = (248 + 127) / (248 + 79 + 45 + 127)\n",
    "# recall of surviving = sensitivity = 127 / (79 + 127)\n",
    "# recall of not surviving = specificity = 248 / (248 + 5)\n",
    "# precision of surviving = 127 / (45 + 127)\n",
    "# precision of not surviving = 248 / (248 + 79)\n",
    "# false negative = 79 / (248 + 79)\n",
    "\n",
    "print('Accuracy of random forest classifier on TRAIN datat: {:.2f}'\n",
    "     .format(rf.score(X_train, y_train)))\n",
    "print()\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "print()\n",
    "print(classification_report(y_train, y_pred))\n",
    "\n",
    "print('Accuracy of output when model is run on TEST data:')\n",
    "print(rf.score(X_test, y_test))\n",
    "# print()\n",
    "# print(confusion_matrix(y_train, y_pred))\n",
    "# print()\n",
    "# print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first random forest classifier setting min_samples_leaf = 1 and max_depth = 20 gave MUCH better in-sample results with an accuracy of 98%, but its accuracy on the test data was only 71% suggesting the model was overfit for the data. So I'll go with the second classifier with the min_samples_leaf to 5 and decreasing your max_depth to 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Save the best model in forest_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_fit = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=5,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=3, \n",
    "                            random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Nearest Neighbor:\n",
    "\n",
    "Accuracy of KNN classifier on training set: 0.76\n",
    "[[239  54]\n",
    " [ 65 141]]\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.79      0.82      0.80       293\n",
    "           1       0.72      0.68      0.70       206\n",
    "\n",
    "   micro avg       0.76      0.76      0.76       499\n",
    "   macro avg       0.75      0.75      0.75       499\n",
    "weighted avg       0.76      0.76      0.76       499\n",
    "\n",
    "Accuracy of KNN classifier on test set: 0.67\n",
    "\n",
    "Random Forest Classifier:\n",
    "\n",
    "for features ['pclass','age','fare','sibsp','parch']:\n",
    "[0.31756957 0.13479889 0.39019831 0.07086815 0.08656508]\n",
    "\n",
    "Accuracy of random forest classifier on TRAIN datat: 0.75\n",
    "\n",
    "[[247  46]\n",
    " [ 79 127]]\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.76      0.84      0.80       293\n",
    "           1       0.73      0.62      0.67       206\n",
    "\n",
    "   micro avg       0.75      0.75      0.75       499\n",
    "   macro avg       0.75      0.73      0.73       499\n",
    "weighted avg       0.75      0.75      0.75       499\n",
    "\n",
    "Accuracy of output when model is run on TEST data:\n",
    "0.7441860465116279\n",
    "\n",
    "Going with K-Nearest Neighbor model setting k = 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "Once you have determined which algorithm (with metaparameters) performs the best, try reducing the number of features to the top 4 features in terms of information gained for each feature individually. That is, how close do we get to predicting accurately the survival with each feature?\n",
    "\n",
    "1. Compute the information gained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create a new dataframe with top 4 features (train_df_reduced)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Use the top performing algorithm with the metaparameters used in that model. Create the object, fit, transform on in-sample data, and evaluate the results. Compare your evaluation metrics with those from the original model (with all the features). Select the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Run your final model on your out-of-sample dataframe (test_df). Evaluatethe results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
