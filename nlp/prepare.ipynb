{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation\n",
    "The end result of this exercise should be a file named prepare.py that defines the requested functions.\n",
    "\n",
    "In this exercise we will be defining some functions to prepare textual data. These functions should apply equally well to both the codeup blog articles and the news articles that were previously acquired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Argument expected for the -c option\r\n",
      "usage: python [option] ... [-c cmd | -m mod | file | -] [arg] ...\r\n",
      "Try `python -h' for more information.\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/sandragraham/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sandragraham/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from acquire_codeup_blog import get_blog_articles\n",
    "import unicodedata\n",
    "import re\n",
    "import json\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('wordnet')\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# We don't need to install nltk, it should come with anaconda, \n",
    "# but nltk does need to download some data.\n",
    "!python -c \n",
    "nltk; nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rumors are true! The time has arrived. Codeup has officially opened applications to our new Data Science career accelerator, with only 25 seats available! This immersive program is one of a kind in San Antonio, and will help you land a job in Glassdoor’s #1 Best Job in America.\n",
      "Data Science is a method of providing actionable intelligence from data. The data revolution has hit San Antonio, resulting in an explosion in Data Scientist positions across companies like USAA, Accenture, Booz Allen Hamilton, and HEB. We’ve even seen UTSA invest $70 M for a Cybersecurity Center and School of Data Science. We built a program to specifically meet the growing demands of this industry.\n",
      "Our program will be 18 weeks long, full-time, hands-on, and project-based. Our curriculum development and instruction is led by Senior Data Scientist, Maggie Giust, who has worked at HEB, Capital Group, and Rackspace, along with input from dozens of practitioners and hiring partners. Students will work with real data sets, realistic problems, and the entire data science pipeline from collection to deployment. They will receive professional development training in resume writing, interviewing, and continuing education to prepare for a smooth transition to the workforce.\n",
      "We focus on applied data science for immediate impact and ROI in a business, which is how we can back it all up with a 6 month tuition refund guarantee – just like our existing Web Dev program. We’re focusing on Data Science with Python, SQL, and ML, covered in 14 modules: 1) Fundamentals; 2) Applied statistics; 3) SQL; 4) Python; 5) Supervised machine learning – regression; 6) Supervised machine learning – classification; 7) Unsupervised machine learning – clustering; 8) Time series analysis; 9) Anomaly detection; 10) Natural language processing; 11) Distributed machine learning; 12) Advanced topics (deep learning, NoSQL, cloud deployment, etc.); 13) Storytelling with data; and 14) Domain expertise development.\n",
      "Applications are now open for Codeup’s first Data Science cohort, which will start class on February 4, 2019. Hurry – there are only 25 seats available! To further our mission of cultivating inclusive growth, scholarships will be available to women, minorities, LGBTQIA+ individuals, veterans, first responders, and people relocating to San Antonio.\n",
      "If you want to learn about joining our program or hiring our graduates, email datascience@codeup.com!\n"
     ]
    }
   ],
   "source": [
    "articles = get_blog_articles()\n",
    "article_index = 0\n",
    "article = articles[article_index]['content']\n",
    "original = article\n",
    "print(article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Define a function named basic_clean. It should take in a string and apply some basic text cleaning to it:\n",
    "    - lowercase everything\n",
    "    - normalize unicode characters\n",
    "    - replace anything that is not a letter, number, whitespace or a single quote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the rumors are true the time has arrived codeup has officially opened applications to our new data science career accelerator with only 25 seats available this immersive program is one of a kind in san antonio and will help you land a job in glassdoors 1 best job in america data science is a method of providing actionable intelligence from data the data revolution has hit san antonio resulting in an explosion in data scientist positions across companies like usaa accenture booz allen hamilton and heb weve even seen utsa invest 70 m for a cybersecurity center and school of data science we built a program to specifically meet the growing demands of this industry our program will be 18 weeks long full time hands on and project based our curriculum development and instruction is led by senior data scientist maggie giust who has worked at heb capital group and rackspace along with input from dozens of practitioners and hiring partners students will work with real data sets realistic problems and the entire data science pipeline from collection to deployment they will receive professional development training in resume writing interviewing and continuing education to prepare for a smooth transition to the workforce we focus on applied data science for immediate impact and roi in a business which is how we can back it all up with a 6 month tuition refund guarantee just like our existing web dev program were focusing on data science with python sql and ml covered in 14 modules 1 fundamentals 2 applied statistics 3 sql 4 python 5 supervised machine learning regression 6 supervised machine learning classification 7 unsupervised machine learning clustering 8 time series analysis 9 anomaly detection 10 natural language processing 11 distributed machine learning 12 advanced topics deep learning nosql cloud deployment etc 13 storytelling with data and 14 domain expertise development applications are now open for codeups first data science cohort which will start class on february 4 2019 hurry there are only 25 seats available to further our mission of cultivating inclusive growth scholarships will be available to women minorities lgbtqia individuals veterans first responders and people relocating to san antonio if you want to learn about joining our program or hiring our graduates email datascience codeup com\n"
     ]
    }
   ],
   "source": [
    "def basic_clean(article):\n",
    "    new_article = article.lower()\n",
    "    new_article = re.sub(r'\\s', ' ', new_article)\n",
    "    normalized = unicodedata.normalize('NFKD', new_article)\\\n",
    "                .encode('ascii', 'ignore')\\\n",
    "                .decode('utf-8')\n",
    "    without_special_chars = re.sub(r'[^\\w\\s]', ' ', normalized)\n",
    "    word_list = without_special_chars.split()\n",
    "    word_list = ' '.join(word_list)\n",
    "    return word_list\n",
    "\n",
    "article = basic_clean(article)\n",
    "print(article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Define a function named tokenize. It should take in a string and tokenize all the words in the string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the rumors are true the time has arrived codeup has officially opened applications to our new data science career accelerator with only 25 seats available this immersive program is one of a kind in san antonio and will help you land a job in glassdoors 1 best job in america data science is a method of providing actionable intelligence from data the data revolution has hit san antonio resulting in an explosion in data scientist positions across companies like usaa accenture booz allen hamilton and heb weve even seen utsa invest 70 m for a cybersecurity center and school of data science we built a program to specifically meet the growing demands of this industry our program will be 18 weeks long full time hands on and project based our curriculum development and instruction is led by senior data scientist maggie giust who has worked at heb capital group and rackspace along with input from dozens of practitioners and hiring partners students will work with real data sets realistic problems and the entire data science pipeline from collection to deployment they will receive professional development training in resume writing interviewing and continuing education to prepare for a smooth transition to the workforce we focus on applied data science for immediate impact and roi in a business which is how we can back it all up with a 6 month tuition refund guarantee just like our existing web dev program were focusing on data science with python sql and ml covered in 14 modules 1 fundamentals 2 applied statistics 3 sql 4 python 5 supervised machine learning regression 6 supervised machine learning classification 7 unsupervised machine learning clustering 8 time series analysis 9 anomaly detection 10 natural language processing 11 distributed machine learning 12 advanced topics deep learning nosql cloud deployment etc 13 storytelling with data and 14 domain expertise development applications are now open for codeups first data science cohort which will start class on february 4 2019 hurry there are only 25 seats available to further our mission of cultivating inclusive growth scholarships will be available to women minorities lgbtqia individuals veterans first responders and people relocating to san antonio if you want to learn about joining our program or hiring our graduates email datascience codeup com\n"
     ]
    }
   ],
   "source": [
    "def tokenize(article):\n",
    "    tokenizer = nltk.tokenize.ToktokTokenizer()\n",
    "    new_article = tokenizer.tokenize(article, return_str=True)\n",
    "    return new_article\n",
    "\n",
    "article = tokenize(article)\n",
    "print(article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Define a function named stem. It should accept some text and return the text after applying stemming to all the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and           13\n",
      "data          13\n",
      "to             9\n",
      "a              8\n",
      "in             8\n",
      "scienc         7\n",
      "our            7\n",
      "will           6\n",
      "the            6\n",
      "with           6\n",
      "learn          6\n",
      "of             6\n",
      "program        5\n",
      "ha             4\n",
      "machin         4\n",
      "for            4\n",
      "on             4\n",
      "is             4\n",
      "we             3\n",
      "codeup         3\n",
      "san            3\n",
      "from           3\n",
      "time           3\n",
      "avail          3\n",
      "antonio        3\n",
      "develop        3\n",
      "are            3\n",
      "appli          2\n",
      "4              2\n",
      "deploy         2\n",
      "              ..\n",
      "com            1\n",
      "process        1\n",
      "7              1\n",
      "individu       1\n",
      "career         1\n",
      "18             1\n",
      "entir          1\n",
      "focus          1\n",
      "allen          1\n",
      "11             1\n",
      "domain         1\n",
      "respond        1\n",
      "start          1\n",
      "america        1\n",
      "languag        1\n",
      "method         1\n",
      "industri       1\n",
      "cloud          1\n",
      "pipelin        1\n",
      "intellig       1\n",
      "revolut        1\n",
      "classif        1\n",
      "best           1\n",
      "senior         1\n",
      "realist        1\n",
      "true           1\n",
      "cybersecur     1\n",
      "group          1\n",
      "growth         1\n",
      "roi            1\n",
      "Length: 233, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def print_stop_words(article):\n",
    "    # Create the nltk stemmer object, then use it\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    stems = [ps.stem(word) for word in article.split()]\n",
    "    print(pd.Series(stems).value_counts())\n",
    "\n",
    "print_stop_words(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the rumors are true the time has arrived codeup has officially opened applications to our new data science career accelerator with only 25 seats available this immersive program is one of a kind in san antonio and will help you land a job in glassdoors 1 best job in america data science is a method of providing actionable intelligence from data the data revolution has hit san antonio resulting in an explosion in data scientist positions across companies like usaa accenture booz allen hamilton and heb weve even seen utsa invest 70 m for a cybersecurity center and school of data science we built a program to specifically meet the growing demands of this industry our program will be 18 weeks long full time hands on and project based our curriculum development and instruction is led by senior data scientist maggie giust who has worked at heb capital group and rackspace along with input from dozens of practitioners and hiring partners students will work with real data sets realistic problems and the entire data science pipeline from collection to deployment they will receive professional development training in resume writing interviewing and continuing education to prepare for a smooth transition to the workforce we focus on applied data science for immediate impact and roi in a business which is how we can back it all up with a 6 month tuition refund guarantee just like our existing web dev program were focusing on data science with python sql and ml covered in 14 modules 1 fundamentals 2 applied statistics 3 sql 4 python 5 supervised machine learning regression 6 supervised machine learning classification 7 unsupervised machine learning clustering 8 time series analysis 9 anomaly detection 10 natural language processing 11 distributed machine learning 12 advanced topics deep learning nosql cloud deployment etc 13 storytelling with data and 14 domain expertise development applications are now open for codeups first data science cohort which will start class on february 4 2019 hurry there are only 25 seats available to further our mission of cultivating inclusive growth scholarships will be available to women minorities lgbtqia individuals veterans first responders and people relocating to san antonio if you want to learn about joining our program or hiring our graduates email datascience codeup com'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stem(article):\n",
    "    ps = nltk.stem.PorterStemmer()\n",
    "    article_stemmed = ''.join([ps.stem(word) for word in article])\n",
    "    return article_stemmed\n",
    "\n",
    "article_stemmed = stem(article)\n",
    "article_stemmed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Define a function named lemmatize. It should accept some text and return the text after applying lemmatization to each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the rumors are true the time has arrived codeup has officially opened applications to our new data science career accelerator with only 25 seats available this immersive program is one of a kind in san antonio and will help you land a job in glassdoors 1 best job in america data science is a method of providing actionable intelligence from data the data revolution has hit san antonio resulting in an explosion in data scientist positions across companies like usaa accenture booz allen hamilton and heb weve even seen utsa invest 70 m for a cybersecurity center and school of data science we built a program to specifically meet the growing demands of this industry our program will be 18 weeks long full time hands on and project based our curriculum development and instruction is led by senior data scientist maggie giust who has worked at heb capital group and rackspace along with input from dozens of practitioners and hiring partners students will work with real data sets realistic problems and the entire data science pipeline from collection to deployment they will receive professional development training in resume writing interviewing and continuing education to prepare for a smooth transition to the workforce we focus on applied data science for immediate impact and roi in a business which is how we can back it all up with a 6 month tuition refund guarantee just like our existing web dev program were focusing on data science with python sql and ml covered in 14 modules 1 fundamentals 2 applied statistics 3 sql 4 python 5 supervised machine learning regression 6 supervised machine learning classification 7 unsupervised machine learning clustering 8 time series analysis 9 anomaly detection 10 natural language processing 11 distributed machine learning 12 advanced topics deep learning nosql cloud deployment etc 13 storytelling with data and 14 domain expertise development applications are now open for codeups first data science cohort which will start class on february 4 2019 hurry there are only 25 seats available to further our mission of cultivating inclusive growth scholarships will be available to women minorities lgbtqia individuals veterans first responders and people relocating to san antonio if you want to learn about joining our program or hiring our graduates email datascience codeup com\n"
     ]
    }
   ],
   "source": [
    "def lemmatize(article):\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    lemmatized_words = [wnl.lemmatize(word) for word in article]\n",
    "    article_lemmatized = ''.join(lemmatized_words)\n",
    "    return article_lemmatized\n",
    "    \n",
    "article_lemmatized = lemmatize(article)\n",
    "print(article_lemmatized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Define a function named remove_stopwords. It should accept some text and return the text after removing all the stopwords.\n",
    "\n",
    "    This function should define two optional parameters, extra_words and exclude_words. These parameters should define any additional stop words to include, and any words that we don't want to remove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rumors true time arrived officially opened applications new data science career accelerator 25 seats available immersive program one kind san antonio help land job glassdoors 1 best job america data science method providing actionable intelligence data data revolution hit san antonio resulting explosion data scientist positions across companies like usaa accenture booz allen hamilton heb weve even seen utsa invest 70 cybersecurity center school data science built program specifically meet growing demands industry program 18 weeks long full time hands project based curriculum development instruction led senior data scientist maggie giust worked heb capital group rackspace along input dozens practitioners hiring partners students work real data sets realistic problems entire data science pipeline collection deployment receive professional development training resume writing interviewing continuing education prepare smooth transition workforce focus applied data science immediate impact roi business back 6 month tuition refund guarantee like existing web dev program focusing data science python sql ml covered 14 modules 1 fundamentals 2 applied statistics 3 sql 4 python 5 supervised machine learning regression 6 supervised machine learning classification 7 unsupervised machine learning clustering 8 time series analysis 9 anomaly detection 10 natural language processing 11 distributed machine learning 12 advanced topics deep learning nosql cloud deployment etc 13 storytelling data 14 domain expertise development applications open codeups first data science cohort start class february 4 2019 hurry 25 seats available mission cultivating inclusive growth scholarships available women minorities lgbtqia individuals veterans first responders people relocating san antonio want learn joining program hiring graduates email datascience com\n"
     ]
    }
   ],
   "source": [
    "def remove_stopwords(article, extra_words, exclude_words):\n",
    "    # get basic stopword list\n",
    "    stopword_list = stopwords.words('english')\n",
    "    # add extra words\n",
    "    stopword_list = stopword_list + extra_words\n",
    "    # remove excluded words\n",
    "    stopword_list = [x for x in stopword_list if x not in exclude_words]\n",
    "    \n",
    "    without_stopwords = [word for word in article.split(' ') if word not in stopword_list]\n",
    "    article_without_stopwords = ' '.join(without_stopwords)\n",
    "    return article_without_stopwords\n",
    "\n",
    "extra_words = ['codeup']\n",
    "exclude_words = ['']\n",
    "article_without_stopwords = remove_stopwords(article, extra_words, exclude_words)\n",
    "print(article_without_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Define a function named prep_article that takes in the dictionary representing an article and returns a dictionary that looks like this:\n",
    "```\n",
    "{\n",
    "    'title': 'the original title',\n",
    "    'original': original,\n",
    "    'stemmed': article_stemmed,\n",
    "    'lemmatized': article_lemmatized,\n",
    "    'clean': article_without_stopwords\n",
    "}\n",
    "```\n",
    "Note that if the orignal dictionary has a title property, it should remain unchanged (same goes for the category property)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'codeups-data-science-career-accelerator-is-here',\n",
       " 'original': 'The rumors are true! The time has arrived. Codeup has officially opened applications to our new Data Science career accelerator, with only 25 seats available! This immersive program is one of a kind in San Antonio, and will help you land a job in\\xa0Glassdoor’s #1 Best Job in America.\\nData Science is a method of providing actionable intelligence from data.\\xa0The data revolution has hit San Antonio,\\xa0resulting in an explosion in Data Scientist positions\\xa0across companies like USAA, Accenture, Booz Allen Hamilton, and HEB. We’ve even seen\\xa0UTSA invest $70 M for a Cybersecurity Center and School of Data Science.\\xa0We built a program to specifically meet the growing demands of this industry.\\nOur program will be 18 weeks long, full-time, hands-on, and project-based. Our curriculum development and instruction is led by Senior Data Scientist, Maggie Giust, who has worked at HEB, Capital Group, and Rackspace, along with input from dozens of practitioners and hiring partners. Students will work with real data sets, realistic problems, and the entire data science pipeline from collection to deployment. They will receive professional development training in resume writing, interviewing, and continuing education to prepare for a smooth transition to the workforce.\\nWe focus on applied data science for immediate impact and ROI in a business, which is how we can back it all up with a 6 month tuition refund guarantee – just like our existing Web Dev program. We’re focusing on Data Science with Python, SQL, and ML, covered in\\xa014 modules: 1) Fundamentals; 2) Applied statistics; 3) SQL; 4) Python; 5) Supervised machine learning – regression; 6) Supervised machine learning – classification; 7) Unsupervised machine learning – clustering; 8) Time series analysis; 9) Anomaly detection; 10) Natural language processing; 11) Distributed machine learning; 12) Advanced topics (deep learning, NoSQL, cloud deployment, etc.); 13) Storytelling with data; and 14) Domain expertise development.\\nApplications are now open\\xa0for Codeup’s first Data Science cohort, which will start class on February 4, 2019. Hurry – there are only 25 seats available! To further our mission of cultivating inclusive growth, scholarships will be available to women, minorities, LGBTQIA+ individuals, veterans, first responders, and people relocating to San Antonio.\\nIf you want to learn about joining our program or hiring our graduates, email datascience@codeup.com!',\n",
       " 'category': ['blog'],\n",
       " 'stemmed': 'the rumors are true the time has arrived codeup has officially opened applications to our new data science career accelerator with only 25 seats available this immersive program is one of a kind in san antonio and will help you land a job in glassdoors 1 best job in america data science is a method of providing actionable intelligence from data the data revolution has hit san antonio resulting in an explosion in data scientist positions across companies like usaa accenture booz allen hamilton and heb weve even seen utsa invest 70 m for a cybersecurity center and school of data science we built a program to specifically meet the growing demands of this industry our program will be 18 weeks long full time hands on and project based our curriculum development and instruction is led by senior data scientist maggie giust who has worked at heb capital group and rackspace along with input from dozens of practitioners and hiring partners students will work with real data sets realistic problems and the entire data science pipeline from collection to deployment they will receive professional development training in resume writing interviewing and continuing education to prepare for a smooth transition to the workforce we focus on applied data science for immediate impact and roi in a business which is how we can back it all up with a 6 month tuition refund guarantee just like our existing web dev program were focusing on data science with python sql and ml covered in 14 modules 1 fundamentals 2 applied statistics 3 sql 4 python 5 supervised machine learning regression 6 supervised machine learning classification 7 unsupervised machine learning clustering 8 time series analysis 9 anomaly detection 10 natural language processing 11 distributed machine learning 12 advanced topics deep learning nosql cloud deployment etc 13 storytelling with data and 14 domain expertise development applications are now open for codeups first data science cohort which will start class on february 4 2019 hurry there are only 25 seats available to further our mission of cultivating inclusive growth scholarships will be available to women minorities lgbtqia individuals veterans first responders and people relocating to san antonio if you want to learn about joining our program or hiring our graduates email datascience codeup com',\n",
       " 'lemmatized': 'the rumors are true the time has arrived codeup has officially opened applications to our new data science career accelerator with only 25 seats available this immersive program is one of a kind in san antonio and will help you land a job in glassdoors 1 best job in america data science is a method of providing actionable intelligence from data the data revolution has hit san antonio resulting in an explosion in data scientist positions across companies like usaa accenture booz allen hamilton and heb weve even seen utsa invest 70 m for a cybersecurity center and school of data science we built a program to specifically meet the growing demands of this industry our program will be 18 weeks long full time hands on and project based our curriculum development and instruction is led by senior data scientist maggie giust who has worked at heb capital group and rackspace along with input from dozens of practitioners and hiring partners students will work with real data sets realistic problems and the entire data science pipeline from collection to deployment they will receive professional development training in resume writing interviewing and continuing education to prepare for a smooth transition to the workforce we focus on applied data science for immediate impact and roi in a business which is how we can back it all up with a 6 month tuition refund guarantee just like our existing web dev program were focusing on data science with python sql and ml covered in 14 modules 1 fundamentals 2 applied statistics 3 sql 4 python 5 supervised machine learning regression 6 supervised machine learning classification 7 unsupervised machine learning clustering 8 time series analysis 9 anomaly detection 10 natural language processing 11 distributed machine learning 12 advanced topics deep learning nosql cloud deployment etc 13 storytelling with data and 14 domain expertise development applications are now open for codeups first data science cohort which will start class on february 4 2019 hurry there are only 25 seats available to further our mission of cultivating inclusive growth scholarships will be available to women minorities lgbtqia individuals veterans first responders and people relocating to san antonio if you want to learn about joining our program or hiring our graduates email datascience codeup com',\n",
       " 'clean': 'rumors true time arrived officially opened applications new data science career accelerator 25 seats available immersive program one kind san antonio help land job glassdoors 1 best job america data science method providing actionable intelligence data data revolution hit san antonio resulting explosion data scientist positions across companies like usaa accenture booz allen hamilton heb weve even seen utsa invest 70 cybersecurity center school data science built program specifically meet growing demands industry program 18 weeks long full time hands project based curriculum development instruction led senior data scientist maggie giust worked heb capital group rackspace along input dozens practitioners hiring partners students work real data sets realistic problems entire data science pipeline collection deployment receive professional development training resume writing interviewing continuing education prepare smooth transition workforce focus applied data science immediate impact roi business back 6 month tuition refund guarantee like existing web dev program focusing data science python sql ml covered 14 modules 1 fundamentals 2 applied statistics 3 sql 4 python 5 supervised machine learning regression 6 supervised machine learning classification 7 unsupervised machine learning clustering 8 time series analysis 9 anomaly detection 10 natural language processing 11 distributed machine learning 12 advanced topics deep learning nosql cloud deployment etc 13 storytelling data 14 domain expertise development applications open codeups first data science cohort start class february 4 2019 hurry 25 seats available mission cultivating inclusive growth scholarships available women minorities lgbtqia individuals veterans first responders people relocating san antonio want learn joining program hiring graduates email datascience com'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prep_article(this_dict):\n",
    "    keys = list(this_dict.keys())\n",
    "    this_entry = {\n",
    "         'title': this_dict['title'],\n",
    "         'original': original,\n",
    "         'category': [this_dict['category'] if 'category' in keys else 'blog'],\n",
    "         'stemmed': article_stemmed,\n",
    "         'lemmatized': article_lemmatized,\n",
    "         'clean': article_without_stopwords\n",
    "        }\n",
    "    return this_entry\n",
    "\n",
    "this_dict = articles[article_index]\n",
    "prep_article(this_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Define a function named prepare_article_data that takes in the list of articles dictionaries, applies the prep_article function to each one, and returns the transformed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Argument expected for the -c option\r\n",
      "usage: python [option] ... [-c cmd | -m mod | file | -] [arg] ...\r\n",
      "Try `python -h' for more information.\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/sandragraham/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sandragraham/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from acquire_codeup_blog import get_blog_articles\n",
    "import unicodedata\n",
    "import re\n",
    "import json\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('wordnet')\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# We don't need to install nltk, it should come with anaconda, \n",
    "# but nltk does need to download some data.\n",
    "!python -c \n",
    "nltk; nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_clean(article):\n",
    "    '''\n",
    "    take in a string (article) and return it after applying some basic text cleaning to it:\n",
    "        - lowercase everything\n",
    "        - normalize unicode characters\n",
    "        - replace anything that is not a letter, number, whitespace or a single quote\n",
    "    '''\n",
    "    new_article = article.lower()\n",
    "    new_article = re.sub(r'\\s', ' ', new_article)\n",
    "    normalized = unicodedata.normalize('NFKD', new_article)\\\n",
    "                .encode('ascii', 'ignore')\\\n",
    "                .decode('utf-8')\n",
    "    without_special_chars = re.sub(r'[^\\w\\s]', ' ', normalized)\n",
    "    word_list = without_special_chars.split()\n",
    "    word_list = ' '.join(word_list)\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(article):\n",
    "    '''tokenize all the words in the string, article'''\n",
    "    tokenizer = nltk.tokenize.ToktokTokenizer()\n",
    "    new_article = tokenizer.tokenize(article, return_str=True)\n",
    "    return new_article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stop_words(article):\n",
    "    '''accept some text, apply stemming to all of the words,\n",
    "        and print a list of value counts for all the stemmed words'''\n",
    "    # Create the nltk stemmer object, then use it\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    stems = [ps.stem(word) for word in article.split()]\n",
    "    print(pd.Series(stems).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(article):\n",
    "    '''accept a string and return it after applying stemming to all the words'''\n",
    "    ps = nltk.stem.PorterStemmer()\n",
    "    article_stemmed = ''.join([ps.stem(word) for word in article])\n",
    "    return article_stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(article):\n",
    "    '''accept a string and return it after applying lemmatization to each word.'''\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    lemmatized_words = [wnl.lemmatize(word) for word in article]\n",
    "    article_lemmatized = ''.join(lemmatized_words)\n",
    "    return article_lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(article, extra_words, exclude_words):\n",
    "    '''remove all the stopwords, including all the words in extra_words and excluding\n",
    "    all the words in exclude list'''\n",
    "\n",
    "    # get basic stopword list\n",
    "    stopword_list = stopwords.words('english')\n",
    "    # add extra words\n",
    "    stopword_list = stopword_list + extra_words\n",
    "    # remove excluded words\n",
    "    stopword_list = [x for x in stopword_list if x not in exclude_words]\n",
    "    \n",
    "    without_stopwords = [word for word in article.split(' ') if word not in stopword_list]\n",
    "    article_without_stopwords = ' '.join(without_stopwords)\n",
    "    return article_without_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_article(this_dict):\n",
    "    '''\n",
    "    takes in a dictionary representing an article and returns a dictionary that \n",
    "    looks like this:\n",
    "            {\n",
    "             'title': 'the original title',\n",
    "             'original': original,\n",
    "             'stemmed': article_stemmed,\n",
    "             'lemmatized': article_lemmatized,\n",
    "             'clean': article_without_stopwords\n",
    "            }\n",
    "    Note that if the orignal dictionary has a title property, it will remain unchanged \n",
    "    (same goes for the category property).\n",
    "    '''\n",
    "    # put the content section into article and make a copy\n",
    "    article = this_dict['content']\n",
    "    original = article\n",
    "\n",
    "    '''\n",
    "    apply some basic text cleaning to the string, article:\n",
    "        - lowercase everything\n",
    "        - normalize unicode characters\n",
    "        - replace anything that is not a letter, number, whitespace or a single quote\n",
    "    '''\n",
    "    article = basic_clean(article)\n",
    "\n",
    "    '''tokenize all the words in the string, article'''\n",
    "    article = tokenize(article)\n",
    "\n",
    "    '''applying stemming to all the words in the string, article'''\n",
    "    article_stemmed = stem(article)\n",
    "    \n",
    "    ''''apply lemmatization to each word in the string, article'''\n",
    "    article_lemmatized = lemmatize(article)\n",
    "\n",
    "    '''create a list of extra words and another of words to exclude from the stoplist'''\n",
    "    extra_words = ['codeup']\n",
    "    exclude_words = ['']\n",
    "    \n",
    "    '''remove all the stopwords, including all the words in extra_words and excluding\n",
    "    all the words in exclude list'''\n",
    "    article_without_stopwords = remove_stopwords(article, extra_words, exclude_words)\n",
    "\n",
    "    keys = list(this_dict.keys())\n",
    "    \n",
    "    new_dict = {\n",
    "         'title': this_dict['title'],\n",
    "         'original': original,\n",
    "         'category': [this_dict['category'] if 'category' in keys else 'blog'],\n",
    "         'stemmed': article_stemmed,\n",
    "         'lemmatized': article_lemmatized,\n",
    "         'clean': article_without_stopwords\n",
    "        }\n",
    "    return new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_article_data(articles):\n",
    "    # takes in the list of articles dictionaries, \n",
    "    # applies the prep_article function to each one, \n",
    "    # and returns the transformed data.\n",
    "    transformed_articles = []\n",
    "\n",
    "    for article_index in range(len(articles)):\n",
    "        transformed_entry = prep_article(articles[article_index])\n",
    "        transformed_articles.append(transformed_entry.copy())\n",
    "\n",
    "    return transformed_articles\n",
    "\n",
    "articles = get_blog_articles()\n",
    "transformed_data = prepare_article_data(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
