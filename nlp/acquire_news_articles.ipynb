{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This module provides functions for scraping news article data from inshorts.com.\n",
    "'''\n",
    "\n",
    "import os\n",
    "import json\n",
    "import itertools as it\n",
    "from typing import List, Dict\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "BASE_URL = 'https://inshorts.com/en/read'\n",
    "SECTIONS = ['business', 'sports', 'technology', 'entertainment']\n",
    "\n",
    "def handle_article(article: BeautifulSoup) -> Dict[str, str]:\n",
    "    '''\n",
    "    Given a single article, extracts the title and content\n",
    "    '''\n",
    "    return {\n",
    "        'title': article.find(class_='news-card-title').find('a').text.strip(),\n",
    "        'content': (article.find(class_='news-card-content')\n",
    "                    .find('div', attrs={'itemprop': 'articleBody'})\n",
    "                    .text.strip())\n",
    "    }\n",
    "\n",
    "def fetch_section(section: str) -> List[Dict[str, str]]:\n",
    "    '''\n",
    "    Makes a request for the given section and processes all the articles in it\n",
    "    '''\n",
    "    url = f'{BASE_URL}/{section}'\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text)\n",
    "    articles = [handle_article(article) for article in soup.find_all(class_='news-card')]\n",
    "    for article in articles:\n",
    "        article['category'] = section\n",
    "    return articles\n",
    "\n",
    "def get_all_sections() -> List[Dict[str, str]]:\n",
    "    '''\n",
    "    Returns the processed article data for all of the sections we defined in\n",
    "    SECTIONS\n",
    "    '''\n",
    "    sections = [fetch_section(section) for section in SECTIONS]\n",
    "    # flatten out the nested lists with it.chain\n",
    "    return list(it.chain(*sections))\n",
    "\n",
    "def get_news_articles(use_cache=True) -> List[Dict[str, str]]:\n",
    "    if use_cache and os.path.exists('news_articles.json'):\n",
    "        articles = json.load(open('news_articles.json'))\n",
    "    else:\n",
    "        articles = get_all_sections()\n",
    "        json.dump(articles, open('news_articles.json', 'w'))\n",
    "    return articles\n",
    "\n",
    "def get_news_data() -> pd.DataFrame:\n",
    "    '''\n",
    "    Returns all the articles from all the sections as a pandas DataFrame\n",
    "    '''\n",
    "    return pd.DataFrame(get_all_sections())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
