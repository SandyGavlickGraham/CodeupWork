{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aquisition\n",
    "This exercises uses the case.csv and dept.csv files from the san antonio 311 call dataset.\n",
    "\n",
    "1. read into spark environment (df_case, df_dept) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.types as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"local\").appName(\"read\").\\\n",
    "    enableHiveSupport().\\\n",
    "    getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- source_id: string (nullable = true)\n",
      " |-- source_username: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.format(\"csv\").\\\n",
    "    option(\"sep\", \",\").\\\n",
    "    option(\"header\", True).\\\n",
    "    option(\"inferSchema\", True).\\\n",
    "    load(\"sa311/source.csv\")\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+\n",
      "|source_id|     source_username|\n",
      "+---------+--------------------+\n",
      "|   100137|    Merlene Blodgett|\n",
      "|   103582|         Carmen Cura|\n",
      "|   106463|     Richard Sanchez|\n",
      "|   119403|      Betty De Hoyos|\n",
      "|   119555|      Socorro Quiara|\n",
      "|   119868| Michelle San Miguel|\n",
      "|   120752|      Eva T. Kleiber|\n",
      "|   124405|           Lori Lara|\n",
      "|   132408|       Leonard Silva|\n",
      "|   135723|        Amy Cardenas|\n",
      "|   136202|    Michelle Urrutia|\n",
      "|   136979|      Leticia Garcia|\n",
      "|   137943|    Pamela K. Baccus|\n",
      "|   138605|        Marisa Ozuna|\n",
      "|   138650|      Kimberly Green|\n",
      "|   138650|Kimberly Green-Woods|\n",
      "|   138793| Guadalupe Rodriguez|\n",
      "|   138810|       Tawona Martin|\n",
      "|   139342|     Jessica Mendoza|\n",
      "|   139344|        Isis Mendoza|\n",
      "+---------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- case_id: integer (nullable = true)\n",
      " |-- case_opened_date: string (nullable = true)\n",
      " |-- case_closed_date: string (nullable = true)\n",
      " |-- SLA_due_date: string (nullable = true)\n",
      " |-- case_late: string (nullable = true)\n",
      " |-- num_days_late: double (nullable = true)\n",
      " |-- case_closed: string (nullable = true)\n",
      " |-- dept_division: string (nullable = true)\n",
      " |-- service_request_type: string (nullable = true)\n",
      " |-- SLA_days: double (nullable = true)\n",
      " |-- case_status: string (nullable = true)\n",
      " |-- source_id: string (nullable = true)\n",
      " |-- request_address: string (nullable = true)\n",
      " |-- council_district: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_case = spark.read.format(\"csv\").\\\n",
    "    option(\"sep\", \",\").\\\n",
    "    option(\"header\", True).\\\n",
    "    option(\"inferSchema\", True).\\\n",
    "    load(\"sa311/case.csv\")\n",
    "\n",
    "df_case.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[case_id: int, case_opened_date: string, case_closed_date: string, SLA_due_date: string, case_late: string, num_days_late: double, case_closed: string, dept_division: string, service_request_type: string, SLA_days: double, case_status: string, source_id: string, request_address: string, council_district: int]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dept_division: string (nullable = true)\n",
      " |-- dept_name: string (nullable = true)\n",
      " |-- standardized_dept_name: string (nullable = true)\n",
      " |-- dept_subject_to_SLA: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_dept = spark.read.format(\"csv\").\\\n",
    "    option(\"sep\", \",\").\\\n",
    "    option(\"header\", True).\\\n",
    "    option(\"inferSchema\", True).\\\n",
    "    load(\"sa311/dept.csv\")\n",
    "\n",
    "df_dept.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[dept_division: string, dept_name: string, standardized_dept_name: string, dept_subject_to_SLA: string]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dept # note: this is a spark dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. write df_case and df_dept back to disk into their own directories (my_cases and my_depts) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_case.write.format('csv').mode(\"overwrite\").\\\n",
    "    option(\"header\",\"true\").save(\"sa311/my_cases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dept.write.format('csv').mode(\"overwrite\").\\\n",
    "    option(\"header\",\"true\").save(\"sa311/my_depts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Write df_case and df_dept to parquet files (my_cases_parquet and my_depts_parquet) \n",
    "\n",
    "##### Parquet is a very popular columnar storage format for Hadoop.\n",
    "Below will result in an error if you are using Java 11 or 12 due to current bug... 'Unsupported class file major version 56' https://github.com/gettyimages/docker-spark/issues/56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_case.write.format('parquet').mode('overwrite').\\\n",
    "    option('header','true').save('sa311/my_cases_parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dept.write.format('parquet').mode('overwrite').\\\n",
    "    option('header','true').save('sa311/my_depts_parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Read your parquet files back into your spark environment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[case_id: int, case_opened_date: string, case_closed_date: string, SLA_due_date: string, case_late: string, num_days_late: double, case_closed: string, dept_division: string, service_request_type: string, SLA_days: double, case_status: string, source_id: string, request_address: string, council_district: int]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_case = spark.read.format('parquet').\\\n",
    "    option(\"header\", True).\\\n",
    "    option(\"inferSchema\", True).\\\n",
    "    load(\"sa311/my_cases_parquet\")\n",
    "df_case # spark dataframe again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dept = spark.read.format('parquet').\\\n",
    "    option(\"header\", True).\\\n",
    "    option(\"inferSchema\", True).\\\n",
    "    load(\"sa311/my_depts_parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Read case.csv and dept.csv into a pandas dataframe. (cases_pdf, depts_pdf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_id</th>\n",
       "      <th>case_opened_date</th>\n",
       "      <th>case_closed_date</th>\n",
       "      <th>SLA_due_date</th>\n",
       "      <th>case_late</th>\n",
       "      <th>num_days_late</th>\n",
       "      <th>case_closed</th>\n",
       "      <th>dept_division</th>\n",
       "      <th>service_request_type</th>\n",
       "      <th>SLA_days</th>\n",
       "      <th>case_status</th>\n",
       "      <th>source_id</th>\n",
       "      <th>request_address</th>\n",
       "      <th>council_district</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1014127332</td>\n",
       "      <td>1/1/18 0:42</td>\n",
       "      <td>1/1/18 12:29</td>\n",
       "      <td>9/26/20 0:42</td>\n",
       "      <td>NO</td>\n",
       "      <td>-998.508762</td>\n",
       "      <td>YES</td>\n",
       "      <td>Field Operations</td>\n",
       "      <td>Stray Animal</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>Closed</td>\n",
       "      <td>svcCRMLS</td>\n",
       "      <td>2315  EL PASO ST, San Antonio, 78207</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1014127333</td>\n",
       "      <td>1/1/18 0:46</td>\n",
       "      <td>1/3/18 8:11</td>\n",
       "      <td>1/5/18 8:30</td>\n",
       "      <td>NO</td>\n",
       "      <td>-2.012604</td>\n",
       "      <td>YES</td>\n",
       "      <td>Storm Water</td>\n",
       "      <td>Removal Of Obstruction</td>\n",
       "      <td>4.322222</td>\n",
       "      <td>Closed</td>\n",
       "      <td>svcCRMSS</td>\n",
       "      <td>2215  GOLIAD RD, San Antonio, 78223</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1014127334</td>\n",
       "      <td>1/1/18 0:48</td>\n",
       "      <td>1/2/18 7:57</td>\n",
       "      <td>1/5/18 8:30</td>\n",
       "      <td>NO</td>\n",
       "      <td>-3.022338</td>\n",
       "      <td>YES</td>\n",
       "      <td>Storm Water</td>\n",
       "      <td>Removal Of Obstruction</td>\n",
       "      <td>4.320729</td>\n",
       "      <td>Closed</td>\n",
       "      <td>svcCRMSS</td>\n",
       "      <td>102  PALFREY ST W, San Antonio, 78223</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1014127335</td>\n",
       "      <td>1/1/18 1:29</td>\n",
       "      <td>1/2/18 8:13</td>\n",
       "      <td>1/17/18 8:30</td>\n",
       "      <td>NO</td>\n",
       "      <td>-15.011481</td>\n",
       "      <td>YES</td>\n",
       "      <td>Code Enforcement</td>\n",
       "      <td>Front Or Side Yard Parking</td>\n",
       "      <td>16.291887</td>\n",
       "      <td>Closed</td>\n",
       "      <td>svcCRMSS</td>\n",
       "      <td>114  LA GARDE ST, San Antonio, 78223</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1014127336</td>\n",
       "      <td>1/1/18 1:34</td>\n",
       "      <td>1/1/18 13:29</td>\n",
       "      <td>1/1/18 4:34</td>\n",
       "      <td>YES</td>\n",
       "      <td>0.372164</td>\n",
       "      <td>YES</td>\n",
       "      <td>Field Operations</td>\n",
       "      <td>Animal Cruelty(Critical)</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>Closed</td>\n",
       "      <td>svcCRMSS</td>\n",
       "      <td>734  CLEARVIEW DR, San Antonio, 78228</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      case_id case_opened_date case_closed_date  SLA_due_date case_late  \\\n",
       "0  1014127332      1/1/18 0:42     1/1/18 12:29  9/26/20 0:42        NO   \n",
       "1  1014127333      1/1/18 0:46      1/3/18 8:11   1/5/18 8:30        NO   \n",
       "2  1014127334      1/1/18 0:48      1/2/18 7:57   1/5/18 8:30        NO   \n",
       "3  1014127335      1/1/18 1:29      1/2/18 8:13  1/17/18 8:30        NO   \n",
       "4  1014127336      1/1/18 1:34     1/1/18 13:29   1/1/18 4:34       YES   \n",
       "\n",
       "   num_days_late case_closed     dept_division        service_request_type  \\\n",
       "0    -998.508762         YES  Field Operations                Stray Animal   \n",
       "1      -2.012604         YES       Storm Water      Removal Of Obstruction   \n",
       "2      -3.022338         YES       Storm Water      Removal Of Obstruction   \n",
       "3     -15.011481         YES  Code Enforcement  Front Or Side Yard Parking   \n",
       "4       0.372164         YES  Field Operations    Animal Cruelty(Critical)   \n",
       "\n",
       "     SLA_days case_status source_id                        request_address  \\\n",
       "0  999.000000      Closed  svcCRMLS   2315  EL PASO ST, San Antonio, 78207   \n",
       "1    4.322222      Closed  svcCRMSS    2215  GOLIAD RD, San Antonio, 78223   \n",
       "2    4.320729      Closed  svcCRMSS  102  PALFREY ST W, San Antonio, 78223   \n",
       "3   16.291887      Closed  svcCRMSS   114  LA GARDE ST, San Antonio, 78223   \n",
       "4    0.125000      Closed  svcCRMSS  734  CLEARVIEW DR, San Antonio, 78228   \n",
       "\n",
       "   council_district  \n",
       "0                 5  \n",
       "1                 3  \n",
       "2                 3  \n",
       "3                 3  \n",
       "4                 7  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cases_pdf = pd.read_csv(\"sa311/case.csv\", sep=\",\")\n",
    "cases_pdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dept_division</th>\n",
       "      <th>dept_name</th>\n",
       "      <th>standardized_dept_name</th>\n",
       "      <th>dept_subject_to_SLA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>311 Call Center</td>\n",
       "      <td>Customer Service</td>\n",
       "      <td>Customer Service</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brush</td>\n",
       "      <td>Solid Waste Management</td>\n",
       "      <td>Solid Waste</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Clean and Green</td>\n",
       "      <td>Parks and Recreation</td>\n",
       "      <td>Parks &amp; Recreation</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Clean and Green Natural Areas</td>\n",
       "      <td>Parks and Recreation</td>\n",
       "      <td>Parks &amp; Recreation</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Code Enforcement</td>\n",
       "      <td>Code Enforcement Services</td>\n",
       "      <td>DSD/Code Enforcement</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   dept_division                  dept_name  \\\n",
       "0                311 Call Center           Customer Service   \n",
       "1                          Brush     Solid Waste Management   \n",
       "2                Clean and Green       Parks and Recreation   \n",
       "3  Clean and Green Natural Areas       Parks and Recreation   \n",
       "4               Code Enforcement  Code Enforcement Services   \n",
       "\n",
       "  standardized_dept_name dept_subject_to_SLA  \n",
       "0       Customer Service                 YES  \n",
       "1            Solid Waste                 YES  \n",
       "2     Parks & Recreation                 YES  \n",
       "3     Parks & Recreation                 YES  \n",
       "4   DSD/Code Enforcement                 YES  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depts_pdf = pd.read_csv(\"sa311/dept.csv\", sep=\",\")\n",
    "depts_pdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Convert the pandas dataframes into spark dataframes (cases_sdf, depts_sdf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['case_id', 'case_opened_date', 'case_closed_date', 'SLA_due_date',\n",
       "       'case_late', 'num_days_late', 'case_closed', 'dept_division',\n",
       "       'service_request_type', 'SLA_days', 'case_status', 'source_id',\n",
       "       'request_address', 'council_district'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cases_pdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = T.StructType([\n",
    "        T.StructField('case_id', T.StringType()),\n",
    "        T.StructField('case_opened_date', T.StringType()),\n",
    "        T.StructField('case_closed_date', T.StringType()),\n",
    "        T.StructField('SLA_due_date', T.StringType()),\n",
    "        T.StructField('case_late', T.StringType()),\n",
    "        T.StructField('num_days_late', T.StringType()),\n",
    "        T.StructField('case_closed', T.StringType()),\n",
    "        T.StructField('dept_division', T.StringType()),\n",
    "        T.StructField('service_request_type', T.StringType()),\n",
    "        T.StructField('SLA_days', T.StringType()),\n",
    "        T.StructField('case_status', T.StringType()),\n",
    "        T.StructField('source_id', T.StringType()),\n",
    "        T.StructField('request_address', T.StringType()),\n",
    "        T.StructField('council_district', T.StringType())\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases_sdf = spark.createDataFrame(cases_pdf, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------+----------------+------------+---------+-------------+-----------+----------------+--------------------+-----------+-----------+---------+--------------------+----------------+\n",
      "|   case_id|case_opened_date|case_closed_date|SLA_due_date|case_late|num_days_late|case_closed|   dept_division|service_request_type|   SLA_days|case_status|source_id|     request_address|council_district|\n",
      "+----------+----------------+----------------+------------+---------+-------------+-----------+----------------+--------------------+-----------+-----------+---------+--------------------+----------------+\n",
      "|1014127332|     1/1/18 0:42|    1/1/18 12:29|9/26/20 0:42|       NO| -998.5087616|        YES|Field Operations|        Stray Animal|      999.0|     Closed| svcCRMLS|2315  EL PASO ST,...|               5|\n",
      "|1014127333|     1/1/18 0:46|     1/3/18 8:11| 1/5/18 8:30|       NO| -2.012604167|        YES|     Storm Water|Removal Of Obstru...|4.322222222|     Closed| svcCRMSS|2215  GOLIAD RD, ...|               3|\n",
      "+----------+----------------+----------------+------------+---------+-------------+-----------+----------------+--------------------+-----------+-----------+---------+--------------------+----------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cases_sdf.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['dept_division', 'dept_name', 'standardized_dept_name',\n",
       "       'dept_subject_to_SLA'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depts_pdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = T.StructType([\n",
    "        T.StructField('dept_division', T.StringType()),\n",
    "        T.StructField('dept_name', T.StringType()),\n",
    "        T.StructField('standardized_dept_name', T.StringType()),\n",
    "        T.StructField('dept_subject_to_SLA', T.StringType())\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "depts_sdf = spark.createDataFrame(depts_pdf, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------------+----------------------+-------------------+\n",
      "|  dept_division|           dept_name|standardized_dept_name|dept_subject_to_SLA|\n",
      "+---------------+--------------------+----------------------+-------------------+\n",
      "|311 Call Center|    Customer Service|      Customer Service|                YES|\n",
      "|          Brush|Solid Waste Manag...|           Solid Waste|                YES|\n",
      "+---------------+--------------------+----------------------+-------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "depts_sdf.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Convert the spark dataframes back into pandas dataframes. (cases_pdf1, depts_pdf1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_id</th>\n",
       "      <th>case_opened_date</th>\n",
       "      <th>case_closed_date</th>\n",
       "      <th>SLA_due_date</th>\n",
       "      <th>case_late</th>\n",
       "      <th>num_days_late</th>\n",
       "      <th>case_closed</th>\n",
       "      <th>dept_division</th>\n",
       "      <th>service_request_type</th>\n",
       "      <th>SLA_days</th>\n",
       "      <th>case_status</th>\n",
       "      <th>source_id</th>\n",
       "      <th>request_address</th>\n",
       "      <th>council_district</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1014127332</td>\n",
       "      <td>1/1/18 0:42</td>\n",
       "      <td>1/1/18 12:29</td>\n",
       "      <td>9/26/20 0:42</td>\n",
       "      <td>NO</td>\n",
       "      <td>-998.5087616</td>\n",
       "      <td>YES</td>\n",
       "      <td>Field Operations</td>\n",
       "      <td>Stray Animal</td>\n",
       "      <td>999.0</td>\n",
       "      <td>Closed</td>\n",
       "      <td>svcCRMLS</td>\n",
       "      <td>2315  EL PASO ST, San Antonio, 78207</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1014127333</td>\n",
       "      <td>1/1/18 0:46</td>\n",
       "      <td>1/3/18 8:11</td>\n",
       "      <td>1/5/18 8:30</td>\n",
       "      <td>NO</td>\n",
       "      <td>-2.012604167</td>\n",
       "      <td>YES</td>\n",
       "      <td>Storm Water</td>\n",
       "      <td>Removal Of Obstruction</td>\n",
       "      <td>4.322222222</td>\n",
       "      <td>Closed</td>\n",
       "      <td>svcCRMSS</td>\n",
       "      <td>2215  GOLIAD RD, San Antonio, 78223</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1014127334</td>\n",
       "      <td>1/1/18 0:48</td>\n",
       "      <td>1/2/18 7:57</td>\n",
       "      <td>1/5/18 8:30</td>\n",
       "      <td>NO</td>\n",
       "      <td>-3.022337963</td>\n",
       "      <td>YES</td>\n",
       "      <td>Storm Water</td>\n",
       "      <td>Removal Of Obstruction</td>\n",
       "      <td>4.320729167</td>\n",
       "      <td>Closed</td>\n",
       "      <td>svcCRMSS</td>\n",
       "      <td>102  PALFREY ST W, San Antonio, 78223</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1014127335</td>\n",
       "      <td>1/1/18 1:29</td>\n",
       "      <td>1/2/18 8:13</td>\n",
       "      <td>1/17/18 8:30</td>\n",
       "      <td>NO</td>\n",
       "      <td>-15.01148148</td>\n",
       "      <td>YES</td>\n",
       "      <td>Code Enforcement</td>\n",
       "      <td>Front Or Side Yard Parking</td>\n",
       "      <td>16.29188657</td>\n",
       "      <td>Closed</td>\n",
       "      <td>svcCRMSS</td>\n",
       "      <td>114  LA GARDE ST, San Antonio, 78223</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1014127336</td>\n",
       "      <td>1/1/18 1:34</td>\n",
       "      <td>1/1/18 13:29</td>\n",
       "      <td>1/1/18 4:34</td>\n",
       "      <td>YES</td>\n",
       "      <td>0.372164352</td>\n",
       "      <td>YES</td>\n",
       "      <td>Field Operations</td>\n",
       "      <td>Animal Cruelty(Critical)</td>\n",
       "      <td>0.125</td>\n",
       "      <td>Closed</td>\n",
       "      <td>svcCRMSS</td>\n",
       "      <td>734  CLEARVIEW DR, San Antonio, 78228</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      case_id case_opened_date case_closed_date  SLA_due_date case_late  \\\n",
       "0  1014127332      1/1/18 0:42     1/1/18 12:29  9/26/20 0:42        NO   \n",
       "1  1014127333      1/1/18 0:46      1/3/18 8:11   1/5/18 8:30        NO   \n",
       "2  1014127334      1/1/18 0:48      1/2/18 7:57   1/5/18 8:30        NO   \n",
       "3  1014127335      1/1/18 1:29      1/2/18 8:13  1/17/18 8:30        NO   \n",
       "4  1014127336      1/1/18 1:34     1/1/18 13:29   1/1/18 4:34       YES   \n",
       "\n",
       "  num_days_late case_closed     dept_division        service_request_type  \\\n",
       "0  -998.5087616         YES  Field Operations                Stray Animal   \n",
       "1  -2.012604167         YES       Storm Water      Removal Of Obstruction   \n",
       "2  -3.022337963         YES       Storm Water      Removal Of Obstruction   \n",
       "3  -15.01148148         YES  Code Enforcement  Front Or Side Yard Parking   \n",
       "4   0.372164352         YES  Field Operations    Animal Cruelty(Critical)   \n",
       "\n",
       "      SLA_days case_status source_id                        request_address  \\\n",
       "0        999.0      Closed  svcCRMLS   2315  EL PASO ST, San Antonio, 78207   \n",
       "1  4.322222222      Closed  svcCRMSS    2215  GOLIAD RD, San Antonio, 78223   \n",
       "2  4.320729167      Closed  svcCRMSS  102  PALFREY ST W, San Antonio, 78223   \n",
       "3  16.29188657      Closed  svcCRMSS   114  LA GARDE ST, San Antonio, 78223   \n",
       "4        0.125      Closed  svcCRMSS  734  CLEARVIEW DR, San Antonio, 78228   \n",
       "\n",
       "  council_district  \n",
       "0                5  \n",
       "1                3  \n",
       "2                3  \n",
       "3                3  \n",
       "4                7  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cases_pdf1 = cases_sdf.toPandas()\n",
    "cases_pdf1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(841704, 14)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cases_pdf1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dept_division</th>\n",
       "      <th>dept_name</th>\n",
       "      <th>standardized_dept_name</th>\n",
       "      <th>dept_subject_to_SLA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>311 Call Center</td>\n",
       "      <td>Customer Service</td>\n",
       "      <td>Customer Service</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brush</td>\n",
       "      <td>Solid Waste Management</td>\n",
       "      <td>Solid Waste</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Clean and Green</td>\n",
       "      <td>Parks and Recreation</td>\n",
       "      <td>Parks &amp; Recreation</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Clean and Green Natural Areas</td>\n",
       "      <td>Parks and Recreation</td>\n",
       "      <td>Parks &amp; Recreation</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Code Enforcement</td>\n",
       "      <td>Code Enforcement Services</td>\n",
       "      <td>DSD/Code Enforcement</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   dept_division                  dept_name  \\\n",
       "0                311 Call Center           Customer Service   \n",
       "1                          Brush     Solid Waste Management   \n",
       "2                Clean and Green       Parks and Recreation   \n",
       "3  Clean and Green Natural Areas       Parks and Recreation   \n",
       "4               Code Enforcement  Code Enforcement Services   \n",
       "\n",
       "  standardized_dept_name dept_subject_to_SLA  \n",
       "0       Customer Service                 YES  \n",
       "1            Solid Waste                 YES  \n",
       "2     Parks & Recreation                 YES  \n",
       "3     Parks & Recreation                 YES  \n",
       "4   DSD/Code Enforcement                 YES  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depts_pdf1 = depts_sdf.toPandas()\n",
    "depts_pdf1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39, 4)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depts_pdf1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Read from the tables into two spark dataframes (cases_sdf, depts_sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases_sdf = spark.createDataFrame(cases_pdf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cases_sdf.show(5) # never finished running\n",
    "# Apparently, this is too much data for my \n",
    "# laptop to process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "depts_sdf = spark.createDataFrame(depts_pdf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# depts_sdf.show(5) # never finished running\n",
    "# Apparently, this is too much data for my \n",
    "# laptop to process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect\n",
    "Continue working with the acquire file.\n",
    "\n",
    "1. Read the 311 case data into a Spark DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from pyspark.sql import SparkSession, DataFrame, Column, Row, GroupedData, \\\n",
    "    DataFrameNaFunctions, DataFrameStatFunctions, functions, types, Window\n",
    "from pyspark.sql import functions as f\n",
    "import pyspark.sql.types as T\n",
    "from pyspark.sql.functions import round\n",
    "from pyspark.sql.functions import format_string\n",
    "from pyspark.sql.functions import trim, upper\n",
    "from pyspark.sql.functions import substring\n",
    "from pyspark.sql.functions import regexp_extract\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pyspark\n",
    "# import pandas as pd\n",
    "# from pyspark.sql import SparkSession\n",
    "# import pyspark.sql.types as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"local\").appName(\"read\").\\\n",
    "    enableHiveSupport().\\\n",
    "    getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE: Now calling df_case just df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"sa311/case.csv\"\n",
    "df = spark.read.csv(data, header=True, inferSchema=True)\n",
    "\n",
    "# df = spark.read.format(\"csv\").\\\n",
    "#     option(\"sep\", \",\").\\\n",
    "#     option(\"header\", True).\\\n",
    "#     option(\"inferSchema\", True).\\\n",
    "#     load(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Inspect the DataFrame. Are the data types for each column appropriate? Cast the data to appropriate types as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(841704, 14)\n"
     ]
    }
   ],
   "source": [
    "shape = (df.count(), len(df.columns))\n",
    "print(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- case_id: integer (nullable = true)\n",
      " |-- case_opened_date: string (nullable = true)\n",
      " |-- case_closed_date: string (nullable = true)\n",
      " |-- SLA_due_date: string (nullable = true)\n",
      " |-- case_late: string (nullable = true)\n",
      " |-- num_days_late: double (nullable = true)\n",
      " |-- case_closed: string (nullable = true)\n",
      " |-- dept_division: string (nullable = true)\n",
      " |-- service_request_type: string (nullable = true)\n",
      " |-- SLA_days: double (nullable = true)\n",
      " |-- case_status: string (nullable = true)\n",
      " |-- source_id: string (nullable = true)\n",
      " |-- request_address: string (nullable = true)\n",
      " |-- council_district: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_id</th>\n",
       "      <th>case_opened_date</th>\n",
       "      <th>case_closed_date</th>\n",
       "      <th>SLA_due_date</th>\n",
       "      <th>case_late</th>\n",
       "      <th>num_days_late</th>\n",
       "      <th>case_closed</th>\n",
       "      <th>dept_division</th>\n",
       "      <th>service_request_type</th>\n",
       "      <th>SLA_days</th>\n",
       "      <th>case_status</th>\n",
       "      <th>source_id</th>\n",
       "      <th>request_address</th>\n",
       "      <th>council_district</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1014127332</td>\n",
       "      <td>1/1/18 0:42</td>\n",
       "      <td>1/1/18 12:29</td>\n",
       "      <td>9/26/20 0:42</td>\n",
       "      <td>NO</td>\n",
       "      <td>-998.508762</td>\n",
       "      <td>YES</td>\n",
       "      <td>Field Operations</td>\n",
       "      <td>Stray Animal</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>Closed</td>\n",
       "      <td>svcCRMLS</td>\n",
       "      <td>2315  EL PASO ST, San Antonio, 78207</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1014127333</td>\n",
       "      <td>1/1/18 0:46</td>\n",
       "      <td>1/3/18 8:11</td>\n",
       "      <td>1/5/18 8:30</td>\n",
       "      <td>NO</td>\n",
       "      <td>-2.012604</td>\n",
       "      <td>YES</td>\n",
       "      <td>Storm Water</td>\n",
       "      <td>Removal Of Obstruction</td>\n",
       "      <td>4.322222</td>\n",
       "      <td>Closed</td>\n",
       "      <td>svcCRMSS</td>\n",
       "      <td>2215  GOLIAD RD, San Antonio, 78223</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1014127334</td>\n",
       "      <td>1/1/18 0:48</td>\n",
       "      <td>1/2/18 7:57</td>\n",
       "      <td>1/5/18 8:30</td>\n",
       "      <td>NO</td>\n",
       "      <td>-3.022338</td>\n",
       "      <td>YES</td>\n",
       "      <td>Storm Water</td>\n",
       "      <td>Removal Of Obstruction</td>\n",
       "      <td>4.320729</td>\n",
       "      <td>Closed</td>\n",
       "      <td>svcCRMSS</td>\n",
       "      <td>102  PALFREY ST W, San Antonio, 78223</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      case_id case_opened_date case_closed_date  SLA_due_date case_late  \\\n",
       "0  1014127332      1/1/18 0:42     1/1/18 12:29  9/26/20 0:42        NO   \n",
       "1  1014127333      1/1/18 0:46      1/3/18 8:11   1/5/18 8:30        NO   \n",
       "2  1014127334      1/1/18 0:48      1/2/18 7:57   1/5/18 8:30        NO   \n",
       "\n",
       "   num_days_late case_closed     dept_division    service_request_type  \\\n",
       "0    -998.508762         YES  Field Operations            Stray Animal   \n",
       "1      -2.012604         YES       Storm Water  Removal Of Obstruction   \n",
       "2      -3.022338         YES       Storm Water  Removal Of Obstruction   \n",
       "\n",
       "     SLA_days case_status source_id                        request_address  \\\n",
       "0  999.000000      Closed  svcCRMLS   2315  EL PASO ST, San Antonio, 78207   \n",
       "1    4.322222      Closed  svcCRMSS    2215  GOLIAD RD, San Antonio, 78223   \n",
       "2    4.320729      Closed  svcCRMSS  102  PALFREY ST W, San Antonio, 78223   \n",
       "\n",
       "   council_district  \n",
       "0                 5  \n",
       "1                 3  \n",
       "2                 3  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('*').limit(3).toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the days late to weeks late."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_days_late</th>\n",
       "      <th>num_weeks_late</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-998.508762</td>\n",
       "      <td>-142.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.012604</td>\n",
       "      <td>-0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3.022338</td>\n",
       "      <td>-0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-15.011481</td>\n",
       "      <td>-2.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.372164</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_days_late  num_weeks_late\n",
       "0    -998.508762         -142.64\n",
       "1      -2.012604           -0.29\n",
       "2      -3.022338           -0.43\n",
       "3     -15.011481           -2.14\n",
       "4       0.372164            0.05"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import round\n",
    "\n",
    "# Round to two decimal places, \n",
    "# use alias to rename column, \n",
    "# add a new column with a new column name using withColumn.\n",
    "# df.select(\"num_days_late\", round(df.num_days_late / 7.00, 2)\\\n",
    "#   .alias(\"num_weeks_late\")) \\\n",
    "#   .show(5)\n",
    "\n",
    "df.select(\"num_days_late\") \\\n",
    "  .withColumn(\"num_weeks_late\", \n",
    "              round(df.num_days_late / 7, 2)) \\\n",
    "  .limit(10) \\\n",
    "  .toPandas() \\\n",
    "  .head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the council_district from an integer to a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------------------+\n",
      "|council_district|council_district_fixed|\n",
      "+----------------+----------------------+\n",
      "|               5|            0000000005|\n",
      "|               3|            0000000003|\n",
      "|               3|            0000000003|\n",
      "|               3|            0000000003|\n",
      "|               7|            0000000007|\n",
      "+----------------+----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Note that \"%010d\" makes the field have ten digits,\n",
    "# padded with zeros as necessary.\n",
    "from pyspark.sql.functions import format_string\n",
    "df.select(\"council_district\", format_string(\"%010d\", \"council_district\").\\\n",
    "          alias(\"council_district_fixed\")).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the case_closed flag from a string to a Boolean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------------+\n",
      "|case_closed|case_closed_boolean|\n",
      "+-----------+-------------------+\n",
      "|        YES|               true|\n",
      "|        YES|               true|\n",
      "|        YES|               true|\n",
      "|        YES|               true|\n",
      "|        YES|               true|\n",
      "+-----------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"case_closed\", (df[\"case_closed\"] == \"YES\")\\\n",
    "  .alias(\"case_closed_boolean\")) \\\n",
    "  .show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------------+\n",
      "|case_closed|case_closed_date|\n",
      "+-----------+----------------+\n",
      "|         NO|            null|\n",
      "|         NO|            null|\n",
      "|         NO|            null|\n",
      "|         NO|            null|\n",
      "|         NO|            null|\n",
      "+-----------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"case_closed\", \"case_closed_date\")\\\n",
    "  .filter(df[\"case_closed\"] == \"NO\") \\\n",
    "  .show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the address column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------------+\n",
      "|     request_address|request_address_upper|\n",
      "+--------------------+---------------------+\n",
      "|2315  EL PASO ST,...| 2315  EL PASO ST,...|\n",
      "|2215  GOLIAD RD, ...| 2215  GOLIAD RD, ...|\n",
      "|102  PALFREY ST W...| 102  PALFREY ST W...|\n",
      "|114  LA GARDE ST,...| 114  LA GARDE ST,...|\n",
      "|734  CLEARVIEW DR...| 734  CLEARVIEW DR...|\n",
      "+--------------------+---------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Trim whitespace and convert request_address to uppercase\n",
    "from pyspark.sql.functions import trim, upper\n",
    "df.select(\"request_address\", upper(trim(df.request_address)) \\\n",
    "  .alias(\"request_address_upper\")) \\\n",
    "  .show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the zip code from the address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+\n",
      "|     request_address|request_address_zip|\n",
      "+--------------------+-------------------+\n",
      "|2315  EL PASO ST,...|              78207|\n",
      "|2215  GOLIAD RD, ...|              78223|\n",
      "|102  PALFREY ST W...|              78223|\n",
      "|114  LA GARDE ST,...|              78223|\n",
      "|734  CLEARVIEW DR...|              78228|\n",
      "+--------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import substring\n",
    "df.select(\"request_address\", \n",
    "          substring(\"request_address\", -5, 5). \\\n",
    "          alias(\"request_address_zip\")) \\\n",
    "  .show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OR could extract zip code using a regular expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+\n",
      "|     request_address|request_address_zip|\n",
      "+--------------------+-------------------+\n",
      "|2315  EL PASO ST,...|              78207|\n",
      "|2215  GOLIAD RD, ...|              78223|\n",
      "|102  PALFREY ST W...|              78223|\n",
      "|114  LA GARDE ST,...|              78223|\n",
      "|734  CLEARVIEW DR...|              78228|\n",
      "+--------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import regexp_extract\n",
    "df.select(\"request_address\", \n",
    "          regexp_extract(df.request_address \\\n",
    "                           .cast(\"string\"),\"(\\d{5})$\", 1) \\\n",
    "  .alias(\"request_address_zip\")) \\\n",
    "  .show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix the date fields to be of data type timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- case_id: integer (nullable = true)\n",
      " |-- case_opened_date: string (nullable = true)\n",
      " |-- case_closed_date: string (nullable = true)\n",
      " |-- SLA_due_date: string (nullable = true)\n",
      " |-- case_late: string (nullable = true)\n",
      " |-- num_days_late: double (nullable = true)\n",
      " |-- case_closed: string (nullable = true)\n",
      " |-- dept_division: string (nullable = true)\n",
      " |-- service_request_type: string (nullable = true)\n",
      " |-- SLA_days: double (nullable = true)\n",
      " |-- case_status: string (nullable = true)\n",
      " |-- source_id: string (nullable = true)\n",
      " |-- request_address: string (nullable = true)\n",
      " |-- council_district: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"case_opened_date\", \n",
    "                   f.to_timestamp(f.col(\"case_opened_date\"), \n",
    "                                  \"M/d/yy H:mm\")).\\\n",
    "        withColumn(\"case_closed_date\", \n",
    "                   f.to_timestamp(f.col(\"case_closed_date\"),\n",
    "                                  \"M/d/yy H:mm\")).\\\n",
    "        withColumn(\"SLA_due_date\", \n",
    "                   f.to_timestamp(f.col(\"SLA_due_date\"),\n",
    "                                  \"M/d/yy H:mm\"))\n",
    "# We could use the withColumn method as above to add a new column or replace an existing one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- case_id: integer (nullable = true)\n",
      " |-- case_opened_date: timestamp (nullable = true)\n",
      " |-- case_closed_date: timestamp (nullable = true)\n",
      " |-- SLA_due_date: timestamp (nullable = true)\n",
      " |-- case_late: string (nullable = true)\n",
      " |-- num_days_late: double (nullable = true)\n",
      " |-- case_closed: string (nullable = true)\n",
      " |-- dept_division: string (nullable = true)\n",
      " |-- service_request_type: string (nullable = true)\n",
      " |-- SLA_days: double (nullable = true)\n",
      " |-- case_status: string (nullable = true)\n",
      " |-- source_id: string (nullable = true)\n",
      " |-- request_address: string (nullable = true)\n",
      " |-- council_district: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"case_age\", \n",
    "                   f.datediff(f.current_timestamp(), \n",
    "                              \"case_opened_date\")). \\\n",
    "    withColumn(\"days_to_closed\", \n",
    "               f.datediff(\"case_closed_date\", \n",
    "                          \"case_opened_date\")).\\\n",
    "    withColumn(\"case_lifetime\", \n",
    "               f.when(df[\"case_closed\"]==\"NO\", \n",
    "                      f.col(\"case_age\")) \\\n",
    "                .otherwise(f.col(\"days_to_closed\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_opened_date</th>\n",
       "      <th>case_closed_date</th>\n",
       "      <th>days_to_closed</th>\n",
       "      <th>case_age</th>\n",
       "      <th>case_lifetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 00:42:00</td>\n",
       "      <td>2018-01-01 12:29:00</td>\n",
       "      <td>0</td>\n",
       "      <td>501</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01 00:46:00</td>\n",
       "      <td>2018-01-03 08:11:00</td>\n",
       "      <td>2</td>\n",
       "      <td>501</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01 00:48:00</td>\n",
       "      <td>2018-01-02 07:57:00</td>\n",
       "      <td>1</td>\n",
       "      <td>501</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01 01:29:00</td>\n",
       "      <td>2018-01-02 08:13:00</td>\n",
       "      <td>1</td>\n",
       "      <td>501</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01 01:34:00</td>\n",
       "      <td>2018-01-01 13:29:00</td>\n",
       "      <td>0</td>\n",
       "      <td>501</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     case_opened_date    case_closed_date  days_to_closed  case_age  \\\n",
       "0 2018-01-01 00:42:00 2018-01-01 12:29:00               0       501   \n",
       "1 2018-01-01 00:46:00 2018-01-03 08:11:00               2       501   \n",
       "2 2018-01-01 00:48:00 2018-01-02 07:57:00               1       501   \n",
       "3 2018-01-01 01:29:00 2018-01-02 08:13:00               1       501   \n",
       "4 2018-01-01 01:34:00 2018-01-01 13:29:00               0       501   \n",
       "\n",
       "   case_lifetime  \n",
       "0              0  \n",
       "1              2  \n",
       "2              1  \n",
       "3              1  \n",
       "4              0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(\"case_opened_date\",\n",
    "          \"case_closed_date\", \n",
    "          \"days_to_closed\",\n",
    "          \"case_age\",\n",
    "          \"case_lifetime\") \\\n",
    "  .limit(10) \\\n",
    "  .toPandas() \\\n",
    "  .head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+-------------------------------------------+\n",
      "|case_closed|case_late|((case_closed = YES) AND (case_late = YES))|\n",
      "+-----------+---------+-------------------------------------------+\n",
      "|        YES|       NO|                                      false|\n",
      "|        YES|       NO|                                      false|\n",
      "|        YES|       NO|                                      false|\n",
      "|        YES|       NO|                                      false|\n",
      "|        YES|      YES|                                       true|\n",
      "+-----------+---------+-------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "caseClosedFilter = df.case_closed == \"YES\"\n",
    "caseLateFilter = df[\"case_late\"] == \"YES\"\n",
    "\n",
    "df.select(\"case_closed\", \"case_late\", \n",
    "          caseClosedFilter & caseLateFilter) \\\n",
    "  .show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+------------------------------------------+\n",
      "|case_closed|case_late|((case_closed = YES) OR (case_late = YES))|\n",
      "+-----------+---------+------------------------------------------+\n",
      "|        YES|       NO|                                      true|\n",
      "|        YES|       NO|                                      true|\n",
      "|        YES|       NO|                                      true|\n",
      "|        YES|       NO|                                      true|\n",
      "|        YES|      YES|                                      true|\n",
      "+-----------+---------+------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"case_closed\", \"case_late\", \n",
    "          caseClosedFilter | caseLateFilter) \\\n",
    "  .show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the difference in how nulls are treated in the computation:\n",
    "    - true & null = null\n",
    "    - false & null = false\n",
    "    - true | null = true\n",
    "    - false | null = null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using multiple boolean expressions in a filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+\n",
      "|case_closed|case_late|\n",
      "+-----------+---------+\n",
      "|        YES|      YES|\n",
      "|        YES|      YES|\n",
      "|        YES|      YES|\n",
      "|        YES|      YES|\n",
      "|        YES|      YES|\n",
      "+-----------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(caseClosedFilter & caseLateFilter) \\\n",
    "  .select(\"case_closed\", \"case_late\") \\\n",
    "  .show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "is equivalent to..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+\n",
      "|case_closed|case_late|\n",
      "+-----------+---------+\n",
      "|        YES|      YES|\n",
      "|        YES|      YES|\n",
      "|        YES|      YES|\n",
      "|        YES|      YES|\n",
      "|        YES|      YES|\n",
      "+-----------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(caseLateFilter)\\\n",
    "  .filter(caseClosedFilter) \\\n",
    "  .select(\"case_closed\", \"case_late\") \\\n",
    "  .show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
